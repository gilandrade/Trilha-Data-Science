{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gilandrade/Trilha-Data-Science/blob/master/1_2_NumPy_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t-b8HQXI7UU"
   },
   "source": [
    "# <center> Introdução ao NumPy e Pandas - Teoria e Exercícios</center>\n",
    "___\n",
    "\n",
    "## Conteúdo\n",
    "1. [Introdução](#intro)\n",
    "2. [Jupyter Básico](#basics)\n",
    "3. [Pacotes (Packages)](#pacotes)<br>\n",
    "4. [Encerramento](#encerramento)\n",
    "\n",
    "<a id=\"intro\"></a>\n",
    "## 1. Introdução\n",
    "\n",
    "Agora que você já teve uma pequena introdução ao mundo de Machine Learning, vamos te introduzir a uma das ferramentas mais importantes em análise de dados: a biblioteca Pandas, através da linguagem de programação Python. \n",
    "\n",
    "Utilizaremos o Jupyter Notebook para o acompanhamento da aula. Para isso, é pré-requisito sua instalação, bem como o Python 3. Ambos são disponibilizados se você instalar o software Anaconda 3. O formato da aula propõe que o aluno consiga acompanhar o material e fazer os exercícios ao mesmo tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIggjQsWI7UV"
   },
   "source": [
    "<a id=\"basics\"></a>\n",
    "## 2. Jupyter Básico\n",
    "\n",
    "### 2.1. O que é Jupyter?\n",
    "\"Jupyter\" é um acrônimo que significa Julia, Python, and R. Essas linguagens de programação foram as primeiras utilizadas na aplicação Jupyter, mas, atualmente, o notebook também suporta  [muitas outras linguagens](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels).\n",
    "\n",
    "Por se tratar de uma aplicação server-client, o Jupyter Notebook App permite ao usuário fazer a edição e execução de seus notebooks via web browser (Chrome, por exemplo). A aplicação pode ser executada em um PC sem acesso a Internet. \n",
    "\n",
    "- É possível executar um documento notebook step-by-step (uma célula por vez) pressionando shift + enter.\n",
    "- É possível executar todo o notebook em um único passo. Para isso, basta clicar no menu Cell -> Run All.\n",
    "- Para reiniciar o kernel (i.e., o engine), clique no menu Kernel -> Restart. Isso pode ser útil quando você quer reinicializar o processamentos desde o começo (nesse caso, as variáveis são deletadas, arquivos abertos são fechados, etc...).\n",
    "\n",
    "**Keyboard Navigation**\n",
    "\n",
    "Essa interface do Jupyter Notebook foi **otimizada para eficiente uso com o teclado**. Isso é possível porque há dois modos diferentes de atalhos com o teclado: modo de edição (edition mode) e modo de comando (command mode).\n",
    "\n",
    "Os atalhos mais importantes são \"Enter\", que entra no modo de edição, e \"Esc\", que entra no modo de comando.\n",
    "\n",
    "No modo de edição, a maior parte do teclado está disponível para digitar nas células do notebook. Por conta disso, no modo de edição não há muitos atalhos disponíveis. Já no modo de comando, o teclado inteiro pode ser utilizado para atalhos, portanto, existem muito mais atalhos. Se você clicar em *Help->Keyboard Shortcuts*, será possível ver toda a lista de atalhos disponível.\n",
    "\n",
    "Recomenda-se aprender os atalhos do modo de comando na seguinte ordem:\n",
    "\n",
    "- Navegação básica: enter, shift-enter, up/k, down/j\n",
    "- Salvar o notebook: s\n",
    "- Mudar o tipo da célula (code, markdown, etc...): y, m, 1-6, t\n",
    "- Criação de célula: a, b\n",
    "- Edição de célula: x, c, v, d, z\n",
    "- Kernel operations: i, 0 (pressionar duas vezes)\n",
    "\n",
    "Apesar de esses atalhos representarem o que você mais utilizará no cotidiano, existem algumas [dicas e macetes](https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts) que podem melhorar sua experiência com a aplicação Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lYzdj6uI7UW"
   },
   "source": [
    "### 2.2 Execução de células\n",
    "\n",
    "Não podemos aprender Data Science sem antes conhecer nossas ferramentas, né?\n",
    "\n",
    "Clique na célula abaixo e pressione ctrl+Enter para executar o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qxyMASb-I7UW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\") #Lembre-se que shift+enter vai executar a célula atual e selecionar a próxima célula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gnzziMLFI7Ub"
   },
   "source": [
    "Parabéns!!! Você acabou de executar sua primeira linha de código no Jupyter. Foi bem fácil, né?\n",
    "\n",
    "É assim que o notebook funciona, você pode executar o documento célula a célula e observar o que está sendo realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sl6N8Dw8I7Ub"
   },
   "source": [
    "Vamos, agora, acompanhar uma seção sobre os pacotes básicos mais utilizados para análise de dados em Python: o **Numpy** e o **Pandas**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDZkVGOjI7Uc"
   },
   "source": [
    "<a name=\"pacotes\"></a>\n",
    "## 3. Pacotes (Packages)\n",
    "\n",
    "Um *package* é um diretório de scripts Python, também chamados de modules, com um objetivo em comum. Isso significa que cada script é um módulo que define funções, métodos e tipos. E esse módulos estão organizados em *packages*.\n",
    "\n",
    "Quando você inicializa o Jupyter, apenas o package built-in é carregado. Para usar qualquer função, método ou objeto definido em outro módulo, você deve, primeiramente, importá-lo.\n",
    "\n",
    "Vamos tentar fazer isso com o NumPy, um pacote que lida eficientemente com arrays e matrizes, que você certamente utilizará bastante em sua vida com o Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYsV7fiyI7Uc"
   },
   "source": [
    "### 3.1 NumPy\n",
    "\n",
    "NumPy é a abreviação de ‘Numerical Python’ ou ‘Numeric Python’. Ela é uma biblioteca *open-source* (ou seja, é um software cujo código original é disponibilizado livremente e pode ser distribuido e modificado) que oferece suporte à arrays e matrizes multidimensionais, provendo diversas funções matemáticas úteis em computação científica.\n",
    "\n",
    "Mas por que você deveria utilizar o NumPy? É simples! As listas do Python funcionam como as arrays, no entanto, são lentas para utilização com grandes volumes de dados. No ramo de Ciência de Dados, velocidade e recursos durante o processamento são bem importantes! Dessa forma, o NumPy nos possibilita utilizar os objetos arrays, que são bem mais rápidos que as listas tradicionais do Python.\n",
    "\n",
    "O **ndarray** é o objeto fundamental do NumPy. Este objeto é uma matriz N-dimensional, vamos entender melhor como este objeto funciona nas células abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWBF8V3fI7Ud"
   },
   "source": [
    "#### 3.1.1 Importando o NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s2sCbGy_I7Ue"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c17dde29d94f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Primeiramente, o que você acha que aconteceria se tentássemos utilizar algumas coisa de um pacote que ainda não foi carregado?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Nós podemos testar isso com a função array, do módulo numpy, que retorna um array para uma lista dada\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "# Primeiramente, o que você acha que aconteceria se tentássemos utilizar algumas coisa de um pacote que ainda não foi carregado?\n",
    "# Nós podemos testar isso com a função array, do módulo numpy, que retorna um array para uma lista dada\n",
    "array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFGZy00UI7Ug"
   },
   "source": [
    "Como esperado, tivemos um erro. Nós deveríamos carregar o pacote, então.\n",
    "Para fazer isso, utilizamos a keyword 'import' seguida do nome do package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f4iiqKpjI7Uh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o_VSmvBI7Uj"
   },
   "source": [
    "Repare como precisamos especificar qual é o pacote ao qual a função ```array``` pertence. Poderia ficar muito chato se você tivesse que digitar os nomes dos pacotes todas as vezes que quisesse utilizar alguma coisa deles.\n",
    "\n",
    "Para te ajudar com isso, o Python permite que você utilize um alias para o nome do pacote, através da keyword 'as', tornando seu uso um pouco mais prático, como mostrado a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cFPWPeT7I7Uj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rTvJtmoI7Um"
   },
   "source": [
    "Por último, é possível carregar apenas uma parte de um pacote com a expressão  ```from ... import ...```. Fazendo isso, você estará permitido a utilizar apenas a parte que você carregou do pacote, sem a necessidade de especificar o nome do pacote posteriormente. Veja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZgxvN2tiI7Um"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqF1WpJ7I7Uq"
   },
   "source": [
    "Ótimo, você já sabe importar os pacotes que precisar!\n",
    "\n",
    "Vamos observar o porquê o NumPy é tão poderoso e preferível às listas do Python.\n",
    "\n",
    "Imagine que você tenha duas listas de dados de indivíduos, com alturas e pesos, e queira calcular o IMC (Índice de Massa Corporal) de cada um deles, como mostrado abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4BxlI-C-I7Ut"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6d1374b18ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Calculando o IMC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpeso\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0maltura\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "altura = [1.81, 1.77, 1.69, 1.91]\n",
    "peso = [89.0, 77.3, 55.9, 99.4]\n",
    "\n",
    "# Calculando o IMC\n",
    "imc = peso / altura ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCtEhF62I7Uv"
   },
   "source": [
    "Observe que o Python nos retornou um erro porque não é possivel realizar cálculos com listas, para isso vamos utilizar o NumPy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KNMFG6iEI7Uw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.16644791, 24.67362508, 19.57214383, 27.24706011])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando os arrays com o NumPy\n",
    "\n",
    "np_altura = np.array(altura)\n",
    "np_peso = np.array(peso)\n",
    "\n",
    "# Calculando o IMC\n",
    "imc = np_peso / np_altura ** 2\n",
    "imc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0SOdKBbI7Uy"
   },
   "source": [
    "O Numpy consegue realizar perfeitamente as operações elemento a elemento!\n",
    "\n",
    "Mas preste bem atenção, pois algumas operações podem funcionar de forma diferente do que você imagina. Veja o exemplo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tML_YhdJI7Uz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.81, 1.77, 1.69, 1.91, 1.81, 1.77, 1.69, 1.91]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista do Python\n",
    "altura * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YDEKa-xFI7U1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.62, 3.54, 3.38, 3.82])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array\n",
    "np_altura * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcH2OAfDI7U3"
   },
   "source": [
    "#### 3.1.2 Selecionando subconjuntos de NumPy Arrays\n",
    "A seleção de subconjuntos de NumPy arrays funciona de foram similar à listas de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rwniB6TNI7U3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.572143832498863"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retornando o terceiro elemento da array\n",
    "imc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj--wzxrI7U5"
   },
   "source": [
    "Você também pode selecionar subconjuntos baseados em condições, de forma que apenas os valores que satisfazem as condições serão retornados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RwCbDMxwI7U6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.16644791, 27.24706011])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imc[imc > 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zxPjcqzI7U8"
   },
   "source": [
    "Vamos fazer um exercício para fixação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFgrAn-4I7U9"
   },
   "source": [
    "#### Exercício 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xCqSvuZKI7U9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# lista de pesos de castanhas\n",
    "c_peso = [0.946, 0.918, 0.906, 0.904, 0.858, 0.774, 0.652, 0.516, 0.478, 0.404, 0.396, 0.364, 0.342, 0.304, \n",
    "            0.262, 0.208, 0.134, 0.974, 0.792, 0.792, 0.628, 0.552, 0.506, 0.478, 0.462, 0.436, 0.408, 0.378, \n",
    "            0.3, 0.298, 0.268, 0.252, 0.16, 0.114, 0.092, 0.936, 0.894, 0.744, 0.706, 0.694, 0.69, 0.652, 0.518, \n",
    "            0.508, 0.502, 0.5, 0.47, 0.44, 0.39, 0.384]\n",
    "\n",
    "# Importe o numpy como np\n",
    "import numpy as np\n",
    "\n",
    "# Crie um numpy array a partir de c_peso: np_c_peso\n",
    "np_c_peso = np.array(c_peso)\n",
    "\n",
    "# Imprima o tipo de np_c_peso\n",
    "print(type(np_c_peso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "2Q3pveLOI7U_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.57, 41.31, 40.77, 40.68, 38.61, 34.83, 29.34, 23.22, 21.51,\n",
       "       18.18, 17.82, 16.38, 15.39, 13.68, 11.79,  9.36,  6.03, 43.83,\n",
       "       35.64, 35.64, 28.26, 24.84, 22.77, 21.51, 20.79, 19.62, 18.36,\n",
       "       17.01, 13.5 , 13.41, 12.06, 11.34,  7.2 ,  5.13,  4.14, 42.12,\n",
       "       40.23, 33.48, 31.77, 31.23, 31.05, 29.34, 23.31, 22.86, 22.59,\n",
       "       22.5 , 21.15, 19.8 , 17.55, 17.28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_kg_preco = 45.00\n",
    "\n",
    "# Crie um array a partir de c_peso com a quantia gasta em cada compra: np_c_despesa\n",
    "\n",
    "np_c_despesa = np_c_peso * c_kg_preco\n",
    "np_c_despesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xe-lvBwBI7VB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.628"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprima o peso no indíce 20\n",
    "np_c_peso[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-4-5HH1I7VD"
   },
   "source": [
    "#### 3.1.3  Array N-dimensional\n",
    "Vamos verificar o tipo dos arrays criados acima!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LCgv4mtYI7VD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(np_peso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACK51kB7I7VG"
   },
   "source": [
    "**ndarrays** significam arrays N-dimensionais, vamos criar um numpy array multi-dimensional a partir de listas tradicionais do Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xPyc-WqnI7VG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.81,  1.77,  1.69,  1.91],\n",
       "       [89.  , 77.3 , 55.9 , 99.4 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_2d = np.array([[1.81, 1.77, 1.69, 1.91],\n",
    "                  [89.0, 77.3, 55.9, 99.4]])\n",
    "np_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdWHekG8I7VI"
   },
   "source": [
    "Cada sublista da lista corresponde à uma linha da array bi-dimensional criada.\n",
    "Nós podemos verificar o tamanho da array usando o atributo \"shape\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NDV2yCBVI7VI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlRoKTY7I7VK"
   },
   "source": [
    "Podemos ver que o np_2d tem 2 linhas e 4 colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7FwtOqG0I7VK"
   },
   "source": [
    "Assim como a array unidimensional, também podemos selecionar um subconjunto de uma array multi-dimensional, usando o índice da linha e coluna como abaixo.\n",
    "![Subsetting](https://imgur.com/08EIOjy.png)\n",
    "Veja alguns exemplos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "wuhs2K0II7VL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.81, 1.77, 1.69, 1.91])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_2d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9XQL-bOLI7VN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.69"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecionando a altura (primeira linha) do terceiro elemento\n",
    "np_2d[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNYPyUANI7VO"
   },
   "source": [
    "Basicamente nós selecionamos a linha, e a partir daquela linha fazemos outra seleção.\n",
    "\n",
    "Também é possível selecionar utilizando vírgulas dentro de colchetes: array[linha, coluna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "JalM9A2EI7VP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.69"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Primeira linha e terceira colna\n",
    "np_2d[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ksqMjmYEI7VR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.77,  1.69],\n",
       "       [77.3 , 55.9 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Todas as linhas e segunda e terceira colunas\n",
    "np_2d[:, 1:3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcAa54mqI7VT"
   },
   "source": [
    "#### Exercício 3.2\n",
    "\n",
    "Abaixo temos uma lista de listas contendo informações de vendas de castanhas de uma loja. Cada lista representa uma venda que foi realizada. O primeiro elemento de cada lista é o dia que  venda foi feita, o segundo elemento representa o peso das castanhas compradas. Por fim, o terceiro elemento é a quantia paga pelas castanhas.\n",
    "\n",
    "Com isso em mente, faça os seguintes exercícios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UjZhdLusI7VU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "castanha = [[2, 0.946, 66.1], \n",
    "          [2, 0.918, 32.96], \n",
    "          [2, 0.906, 58.76],\n",
    "          [2, 0.904, 29.14], \n",
    "          [2, 0.858, 59.96],\n",
    "          [2, 0.774, 27.77],\n",
    "          [2, 0.652, 42.3],\n",
    "          [2, 0.516, 18.51], \n",
    "          [2, 0.478, 17.15],\n",
    "          [2, 0.404, 28.22], \n",
    "          [2, 0.396, 7.88], \n",
    "          [2, 0.364, 7.24],\n",
    "          [2, 0.342, 22.18], \n",
    "          [2, 0.304, 10.91], \n",
    "          [2, 0.262, 9.41], \n",
    "          [2, 0.208, 4.13],\n",
    "          [2, 0.134, 9.36],\n",
    "          [4, 0.974, 34.95],\n",
    "          [4, 0.792, 51.38],\n",
    "          [4, 0.792, 51.38], \n",
    "          [4, 0.628, 12.48], \n",
    "          [4, 0.552, 19.81], \n",
    "          [4, 0.506, 25], \n",
    "          [4, 0.478, 31], \n",
    "          [4, 0.462, 32.24],\n",
    "          [4, 0.436, 28.28],\n",
    "          [4, 0.408, 14.64],\n",
    "          [4, 0.378, 13.56],\n",
    "          [4, 0.3, 19.46],\n",
    "          [4, 0.298, 10.69],\n",
    "          [4, 0.268, 9.62],\n",
    "          [4, 0.252, 16.34],\n",
    "          [4, 0.16, 3.18],\n",
    "          [4, 0.114, 4.09],\n",
    "          [4, 0.092, 5.97],\n",
    "          [5, 0.936, 65.33],\n",
    "          [5, 0.894, 32.07],\n",
    "          [5, 0.744, 48.28], \n",
    "          [5, 0.706, 25.34],\n",
    "          [5, 0.694, 24.91], \n",
    "          [5, 0.69, 13.72], \n",
    "          [5, 0.652, 42.32], \n",
    "          [5, 0.518, 33.6], \n",
    "          [5, 0.508, 18.23],\n",
    "          [5, 0.502, 35.09],\n",
    "          [5, 0.5, 27.45], \n",
    "          [5, 0.47, 9.35], \n",
    "          [5, 0.44, 28.54],\n",
    "          [5, 0.39, 7.76], \n",
    "          [5, 0.384, 21.08]]\n",
    "\n",
    "# Crie um numpy array 2d a partir de castanha: np_castanha\n",
    "np_castanha = np.array(castanha)\n",
    "\n",
    "# Imprima o tipo de np_castanha\n",
    "print(type(np_castanha))\n",
    "\n",
    "# Imprima a forma de np_castanha\n",
    "np_castanha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "SWkISBQDI7VX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.   ,  0.974, 34.95 ],\n",
       "       [ 4.   ,  0.792, 51.38 ],\n",
       "       [ 4.   ,  0.792, 51.38 ],\n",
       "       [ 4.   ,  0.628, 12.48 ],\n",
       "       [ 4.   ,  0.552, 19.81 ],\n",
       "       [ 4.   ,  0.506, 25.   ],\n",
       "       [ 4.   ,  0.478, 31.   ],\n",
       "       [ 4.   ,  0.462, 32.24 ],\n",
       "       [ 4.   ,  0.436, 28.28 ],\n",
       "       [ 4.   ,  0.408, 14.64 ],\n",
       "       [ 4.   ,  0.378, 13.56 ],\n",
       "       [ 4.   ,  0.3  , 19.46 ],\n",
       "       [ 4.   ,  0.298, 10.69 ],\n",
       "       [ 4.   ,  0.268,  9.62 ],\n",
       "       [ 4.   ,  0.252, 16.34 ],\n",
       "       [ 4.   ,  0.16 ,  3.18 ],\n",
       "       [ 4.   ,  0.114,  4.09 ],\n",
       "       [ 4.   ,  0.092,  5.97 ],\n",
       "       [ 5.   ,  0.936, 65.33 ],\n",
       "       [ 5.   ,  0.894, 32.07 ],\n",
       "       [ 5.   ,  0.744, 48.28 ],\n",
       "       [ 5.   ,  0.706, 25.34 ],\n",
       "       [ 5.   ,  0.694, 24.91 ],\n",
       "       [ 5.   ,  0.69 , 13.72 ],\n",
       "       [ 5.   ,  0.652, 42.32 ],\n",
       "       [ 5.   ,  0.518, 33.6  ],\n",
       "       [ 5.   ,  0.508, 18.23 ],\n",
       "       [ 5.   ,  0.502, 35.09 ],\n",
       "       [ 5.   ,  0.5  , 27.45 ],\n",
       "       [ 5.   ,  0.47 ,  9.35 ],\n",
       "       [ 5.   ,  0.44 , 28.54 ],\n",
       "       [ 5.   ,  0.39 ,  7.76 ],\n",
       "       [ 5.   ,  0.384, 21.08 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecione toda a segunda coluna de np_castanha: np_c_peso\n",
    "np_c_peso = np_castanha[:,1]\n",
    "\n",
    "# Imprima o preço da 14 venda\n",
    "np_castanha[13,2]\n",
    "\n",
    "# Imprima todas as vendas feitas após o dia 2\n",
    "np_castanha[np_castanha[:,0]>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIEqkTlVI7VZ"
   },
   "source": [
    "#### 3.1.4 Estatística básica com NumPy\n",
    "Costumeiramente o primeiro passo para analisar nossos dados é conhecê-los através de estatística descritiva. O NumPy pode ser usado para obter essa visão inicial dos dados mesmo com grande quantidade de observações.\n",
    "\n",
    "Vamos usar alguns atributos do NumPy para começar a analisar nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "sTkUT6xzI7VZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_a_p = np.array([[1.81, 89.0],\n",
    "                  [1.77, 77.3],\n",
    "                  [1.69, 55.9],\n",
    "                  [1.91, 99.4]])\n",
    "\n",
    "# Calculando a media dos pesos\n",
    "np.mean(np_a_p[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "GFAOifpqI7Vc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculando a mediana dos pesos\n",
    "np.median(np_a_p[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Y3z2MNdDI7Vd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.96933562],\n",
       "       [0.96933562, 1.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculando os coeficientes de correlação entre pesos e alturas\n",
    "np.corrcoef(np_a_p[:, 0], np_a_p[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Dd8HC0onI7Vg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.16183776678878"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculando o desvio padrão dos pesos\n",
    "np.std(np_a_p[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "b2taaZh6I7Vh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.6"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculando a soma dos pesos\n",
    "np.sum(np_a_p[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzNkxEpAI7Vj"
   },
   "source": [
    "Alguns desses atributos já estão disponíveis no Python, no entanto, a principal diferença entre eles é a performance. Os atributos do NumPy são mais rápidos na execução do que os básicos do Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cv9uSyMSI7Vj"
   },
   "source": [
    "Lembrando que sempre que tiver dificuldade para entender algum atributo, você pode consultar a documentação do [Numpy](https://numpy.org/doc/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp0AJiz8I7Vk"
   },
   "source": [
    "Agora que aprendemos como o NumPy funciona, vamos aprender sobre uma das bibliotecas mais utilizadas para manipulação de dados em Python, o **Pandas**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jW-2-KjI7Vk"
   },
   "source": [
    "### 3.2 O que é o Pandas?\n",
    "\n",
    "Pandas é uma biblioteca *open source*, que proporciona estruturas de dados e ferramentas de análise de dados de alta performance e fáceis de usar para Python. Vamos entender melhor o que alguns termos significam:\n",
    " - *open source*: assim como o NumPy, seu código original é disponibilizado livremente e pode ser distribuido e modificado. Isso significa que qualquer um pode contribuir para a evolução do Pandas!\n",
    " - alta performance: Pandas é escrito em Python, Cython e C. Isso permite que os cientistas de dados consigam o utilizar para lidar com conjuntos de dados muito grandes (daqueles que o excel não conseguiria nem abrir) e fazer operações sobre esses dados com facilidade. Dessa forma, Pandas torna nosso trabalho melhor e mais fácil provendo ótima performânce.\n",
    " - estruturas de dados e análises de dados: o motivo pelo qual Pandas existe. Muitas vezes precisamos obter algo com significado de dados crus como documentos de textos, tabelas e etc. Pandas é capaz de lidar com esses tipos de dados para que possamos analisá-los.\n",
    "Em resumo, **Pandas fornece estrutura de dados especializadas e ferramentas para manipulação de dados**. Sua ótima performânce, facilidade de uso e comunidade dedicada são as principais razões de sua vasta adoção entre cientistas de dados. Vamos utilizá-lo!\n",
    "Se você está utilizando o Anaconda, já deve ter ele instalado. Senão, é possível achar os passos de instalação [neste link](https://pandas.pydata.org/). <br>\n",
    "\n",
    "\n",
    "### 3.3 Começando com Pandas\n",
    "\n",
    "#### 3.3.1 Como importá-lo?\n",
    "\n",
    "Por algum motivo, todo mundo importa o Pandas da mesma forma, como mostramos abaixo. Aproveitamos também para importar o Numpy, biblioteca que já apresentamos anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "D3lVTBtPI7Vk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qKrzYVYI7Vm"
   },
   "source": [
    "#### 3.3.2 Objetos do Pandas\n",
    "\n",
    "Existem 2 principais tipos de objetos no Pandas: as [*Series*](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series) e os *DataFrames*. As *Series* são sequências de uma dimensão  de elementos (pra ser mais específicos *ndarray*), todos do mesmo tipo de dados, com rótulos/índices (*labels*). São o objeto primário do Pandas, tudo vai funcionar baseado nelas. Pra criar um objeto do tipo *Series*, podemos fazer o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "tlrOSdwAI7Vn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    3.0\n",
       "2    5.0\n",
       "3    NaN\n",
       "4    6.0\n",
       "5    8.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoMUtFTEI7Vp"
   },
   "source": [
    "Podemos ver acima que cada elemento da *Series* tem um rótulo relacionado. Esses rótulos podem ser tanto numéricos quanto de texto! Ao final do objeto temos a informação sobre o tipo de dados da *Series*: nesse caso, números *float64*. <br>\n",
    "O outro objeto principal do Pandas é o [*DataFrame*](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame), que é basicamente uma coleção de *Series* com rótulos em comum. O *DataFrame* é bem parecido com uma tabela de Excel, com seus índices e colunas. Tanto suas linhas quanto suas colunas tem rótulos, nos permitindo acessar qualquer célula pela sua coordenada. Há diversas formas de criar um *DataFrame*, vamos começar com o mais simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNO6qyIfI7Vq"
   },
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6) #estamos criando uma lista de datas entre 01/01/2013 e 06/01/2013. Note que estamos usando uma função do Pandas\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(6, 4), #apenas números aleatórios nas células\n",
    "    index=dates,  #especificando quais são os índices. Eles aceitam até datas como índice! Isso é muito bom para lidar com dados seriados no tempo\n",
    "    columns=list('ABCD')) #especificando como quero que sejam os nomes das colunas passando uma lista de letras\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCFQaOxrI7Vs"
   },
   "source": [
    "Isso é um *DataFrame*! Uma coisa boa do Pandas com o Jupyter Notebook é que eles mostram o *DataFrame* de uma forma bastante amigável. Agora que sabemos sobre as duas principais estruturas de dados do Pandas, podemos aprender sobre os principais métodos e funcionalidades dessa biblioteca, e para isso vamos utilizar dados reais sobre um das marcas mais conhecidas dos desenhos e videogames :)\n",
    "\n",
    "Observação: um *DataFrame* pode ser visto como um dicionário de listas.\n",
    "\n",
    "#### 3.3.3 Carregando o conjunto de dados\n",
    "\n",
    "Um dos tipos de dados mais comuns para se guardar arquivos são os CSVs. O Pandas tem diversas funções para transformar os mais variados tipos de arquivos em *DataFrames*, como csv, excel, json e etc. Nesse exemplo, vamos usar o [leitor de csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM-UjmFTI7Vs"
   },
   "outputs": [],
   "source": [
    "pkmn = pd.read_csv(\n",
    "    './dados/aula_1_pokemon.csv', #o caminho para o arquivo que se quer ler\n",
    "    sep=',') #o caracter utilizado para separar os valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQCKYMjYI7Vu"
   },
   "source": [
    "#### 3.3.4 Visualizações iniciais\n",
    "Ótimo! Acabamos de criar um *DataFrame* a partir de um arquivo csv. Mas como gostamos de verificar as coisas, seria interessante saber algumas coisas como o que os dados contêm, como é, se tem valores nulos e etc. O Pandas tem 4 métodos principais para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0H8TyInJI7Vu"
   },
   "outputs": [],
   "source": [
    "pkmn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSWYqoxFI7Vw"
   },
   "source": [
    "A primeira coisa que gosto de fazer após ler um conjunto de dados em um *DataFrame* é utilizar o método *info()*. Ele mostra informações como:\n",
    " - a classe do objeto criado\n",
    " - o intervalo do índice e quantas linhas de dados se tem\n",
    " - as colunas, seus nomes e tipos de dado\n",
    " - quais os tipos de dados presentes no *DataFrame* e quantas colunas de cada\n",
    " - a quantidade de memória utilizada pelo computador para guardar esses dados\n",
    "\n",
    "Podemos ver que temos uma base sobre Pokémon, com 800 linhas com índices númericos de 0 a 799, 13 colunas de três tipos de dados diferentes, usando cerca de ~76kB de memória RAM. As informações presentes sobre os Pokémons são o número, o nome, o tipo (alguns tem subtipo, mas não todos, por isso dos dados faltantes na coluna *Type 2*), estatísticas de ataque, defesa e velocidade, a geração e a indicação se ele é lendário (como uma espécie mística). <br> Todas essas informações a gente conseguiu descobrir com apenas uma linha de código! Vamos então ver como o *DataFrame* realmente é. Temos dois métodos para isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ly2u3gbBI7Vw"
   },
   "outputs": [],
   "source": [
    "pkmn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFDpCiTlI7Vz"
   },
   "outputs": [],
   "source": [
    "pkmn.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jMRnRWEI7V2"
   },
   "source": [
    "O método *.head()* e *.tail()* mostram, respectivamente, as primeiras e últimas n linhas do *DataFrame* (por padrão, n=5, mas você pode passar qualquer número como parâmetro) mostrando os índices e os nomes das colunas como numa tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snLGHsfkI7V2"
   },
   "outputs": [],
   "source": [
    "pkmn.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6pyg9YmI7V4"
   },
   "source": [
    "Por fim, o método *.describe()* mostra um resumo estatístico de todas as colunas numéricas. É um método bom para ter uma ideia inicial sobre o que ocorre nas colunas de uma perspectiva estatística.\n",
    "\n",
    "#### Exercício 3.3\n",
    "Use o arquivo de jogadores do FIFA Ultimate Team para os exercícios de Pandas. Caso você não conheça, o Ultimate Team (FUT) é um modo de jogo do FIFA onde você monta seu próprio time comprando jogadores do jogo. <br>\n",
    "Substitua os \\____ abaixo para ler o arquivo e siga as instruções para ter as visualizações iniciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1xcUEs4I7V6"
   },
   "outputs": [],
   "source": [
    "# leia o arquivo (tente abrir num editor de texto antes para verificar o separador)\n",
    "fut_players = pd.read_csv(____, sep=____)\n",
    "\n",
    "# mostre as primeiras 10 linhas de dados\n",
    "fut_players.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH2ejCchI7V8"
   },
   "outputs": [],
   "source": [
    "# mostre as últimas 10 linhas de dados\n",
    "fut_players.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nel6P37gI7V-"
   },
   "outputs": [],
   "source": [
    "# use o método .info() no DataFrame\n",
    "fut_players.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YgWsp0FAI7WA"
   },
   "outputs": [],
   "source": [
    "# mostre o resumo estatístico das colunas numericas\n",
    "fut_players.____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QTzo2U5I7WB"
   },
   "source": [
    "### 3.4 Filtrando (*Filtering*) e fatiando (*slicing*) os dados\n",
    "\n",
    "*Filtering* e *slicing* são técnicas utilizadas para isolar partes específicas do *DataFrame*, sejam linhas, colunas ou células. Isso é muito útil pois diversas vezes queremos analisar alguns dados ao invés da base inteira. O Pandas tem ferramentas próprias para isso. <br>\n",
    "\n",
    "#### 3.4.1 *Slicing*\n",
    "\n",
    "No Pandas existem duas principais formas de fatiar os dados, isto é, selecionar apenas uma parte de acordo com as linhas e colunas do *DataFrame*: utilizando o nome das partes ou com os métodos *.loc()* e *.iloc()*. Vamos começar pelo primeiro. Para fazer isso, imagine que queremos apenas os nomes e o poder de ataque dos Pokémons e veja o exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46uivHZcI7WC"
   },
   "outputs": [],
   "source": [
    "pkmn[['Name','Attack']].head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2t9ZGA9I7WF"
   },
   "source": [
    "Duas coisas importantes aqui:\n",
    " - Juntamos o *slicing* com o método *.head()* na mesma linha, para que fosse possível ver o resultado do fatiamento. Ao usar o Pandas é possível e comum fazer esse tipo de agrupamento de operações.\n",
    " - Foram utilizadas chaves duplas [[]] no fatiamento. Ao fazer isso, estou explicitando que quero um objeto do tipo *DataFrame*. Se eu quisesse objetos do tipo *Series* usaria chaves simples. Podemos ver um exemplo disso abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ml4LWZJI7WF"
   },
   "outputs": [],
   "source": [
    "type(pkmn[['Name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVLgmH7lI7WI"
   },
   "outputs": [],
   "source": [
    "type(pkmn['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqRmLi4HI7WL"
   },
   "source": [
    "Outra forma de se obter um objeto do tipo *Series* é passando a coluna como se fosse um atributo do *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GYbEpLNI7WM"
   },
   "outputs": [],
   "source": [
    "pkmn.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWKI_99GI7WN"
   },
   "source": [
    "O único problema desse formato é que colunas cujo nome contém espaços não funcionarão, como é o caso das colunas *Type 1*, *Type 2*, *Sp. Atk* e *Sp. Def*. Para resolver isso, vamos renomeá-las com o método *.rename()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qnf5uL5wI7WO"
   },
   "outputs": [],
   "source": [
    "pkmn.rename(\n",
    "    columns={'Type 1':'Type_1', 'Type 2':'Type_2', 'Sp. Atk':'Sp_Atk','Sp. Def':'Sp_Def'}, #passando o nome antigo e novo como um dicionário\n",
    "    inplace = True #algumas operações com Pandas criam uma cópia do DataFrame e não alteram o objeto em si, alteramos isso mudando o parâmetro inplace para verdadeiro\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lnAsbq4xI7WQ"
   },
   "outputs": [],
   "source": [
    "pkmn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjYNYK1aI7WT"
   },
   "source": [
    "Agora que os nomes foram trocados, podemos obter um objeto *Series* do tipo do Pokémon como a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s5IjJpwNI7WT"
   },
   "outputs": [],
   "source": [
    "pkmn.Type_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R281vnHrI7WV"
   },
   "source": [
    "Outra forma de selecionar partes dos dados é usando os métodos *.loc()* e *.iloc()*.<br>\n",
    "Para usar a localização númerica utilizamos o *iloc*. Como você pode imaginar, a linhas e colunas são ordenadas por números inteiros sequenciais, começando do 0, como nas listas. Dessa forma, se você sabe o número da linha e da coluna, você pode usar o *iloc*. Por exemplo, se quisermos a coluna HP, que é a 6ª, poderíamos fazer o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU3QcQiZI7WV"
   },
   "outputs": [],
   "source": [
    "pkmn.iloc[:,5].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76glpCfwI7WX"
   },
   "source": [
    "A sintaxe do *iloc* é como [x,y], que significa que queremos a (x+1)ª linha e (y+1)ª coluna. Se utilizarmos ':' no lugar de x ou y significa que queremos a coluna ou linha completa, respectivamente. Vamos pegar o HP do Bulbasaur, o primeiro Pokémon do nosso *DataFrame*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xsk3EutuI7WX"
   },
   "outputs": [],
   "source": [
    "print(\"O HP do Bulbasaur é \"+str(pkmn.iloc[0,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGy5jCcgI7Wa"
   },
   "source": [
    "O método *.loc()* usa o rótulo para acessar os valores. Dessa forma, ao invés de passarmos as coordenadas numéricas, passamos o nome da linha e da coluna, como a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcQV_oi3I7Wb"
   },
   "outputs": [],
   "source": [
    "pkmn.loc[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nu5OJQgOI7Wc"
   },
   "source": [
    "No caso, os rótulos das linhas são iguais às suas coordenadas, por isso ficou parecido com o *iloc*. Vamos fazer o teste com as colunas também para ver a diferença. Abaixo pegaremos novamente o HP do Bulbasaur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jMGO5ACI7Wc"
   },
   "outputs": [],
   "source": [
    "print(\"O HP do Bulbasaur é \"+str(pkmn.loc[0,'HP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzRDpdWNI7We"
   },
   "source": [
    "#### 3.4.2 Filtros (*Filtering*)\n",
    "\n",
    "Uma vez sabendo isolar partes do *DataFrame* de acordo com a localização dos dados, podemos partir para isolar de acordo com condições, ou seja, filtrar os dados.\n",
    "Para conseguir fazer isso no Pandas, fazemos o seguinte: passamos uma expressão condicional e o Pandas retorna apenas as partes que teriam a condição como verdade. Para testar isso, vamos ver a defesa média de todas os Pokémons e depois ver se os tipos 'Rock' e 'Steel' tem defesas maiores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t9BIt7O7I7We"
   },
   "outputs": [],
   "source": [
    "pkmn.Defense.mean() #note que operações comuns como média (mean), mediana (median) e soma (sum) são métodos do Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyQ1od9FI7Wg"
   },
   "outputs": [],
   "source": [
    "pkmn.loc[pkmn.Type_1=='Rock'].Defense.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3HYd44rI7Wh"
   },
   "outputs": [],
   "source": [
    "pkmn[pkmn.Type_1=='Steel'].Defense.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ3SSloPI7Wj"
   },
   "source": [
    "De fato, parece que os tipos selecionados tem média acima dos demais Pokémons. Para verificar isso, passamos a condição pkmn.Type_1=='Steel' entre chaves, o que retorna apenas as linhas de tal tipo. Com isso, selecionamos apenas a coluna de defesa e calculamos a média. <br>\n",
    "Vamos ver agora os Pokémons com defesa maior que 150, cujo tipo principal não é 'Rock' nem 'Steel':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZssFNJSI7Wj"
   },
   "outputs": [],
   "source": [
    "pkmn[(pkmn.Defense > 150)&(pkmn.Type_1!='Rock')&(pkmn.Type_1!='Steel')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0yWxF1MI7Wl"
   },
   "source": [
    "Podemos ver acima que é possível juntar condições com os operadores E (&) e OU (|), como vimos no inicio da aula.<br>\n",
    "Vamos dizer agora que você quer apenas alguns Pokémons em específico, por exemplo Venusaur, Charizard e Blastoise. Criar uma condição para cada e uní-las com o operador & pode ser difícil, ainda mais se for uma quantidade grande de opções. Podemos facilitar isso passando uma tupla ao método *.isin()*, como abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hZmFFpNI7Wl"
   },
   "outputs": [],
   "source": [
    "aux = ('Venusaur', 'Charizard', 'Blastoise')\n",
    "pkmn[pkmn.Name.isin(aux)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xqpu5WPI7Wm"
   },
   "source": [
    "Finalmente, podemos criar novos *DataFrames* de um já existente selecionando apenas algumas linhas ou colunas dele:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTkyAPJ3I7Wn"
   },
   "outputs": [],
   "source": [
    "offensive_stats = pkmn[['#','Name','Attack','Sp_Atk','Speed']] #selecionando apenas estatísticas ofensivas\n",
    "defensive_stats = pkmn[['#','Name', 'HP','Defense','Sp_Def']] #selecionando apenas estatísticas defensivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eya67aYTI7Wo"
   },
   "outputs": [],
   "source": [
    "offensive_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9VDvgW8I7Wp"
   },
   "outputs": [],
   "source": [
    "defensive_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bnidkhc7I7Wq"
   },
   "outputs": [],
   "source": [
    "fire_pkmn = pkmn[(pkmn.Type_1=='Fire')|(pkmn.Type_2=='Fire')] #filtrando apenas linhas com algumas condições\n",
    "fire_pkmn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5mYCPdtI7Ws"
   },
   "outputs": [],
   "source": [
    "water_pkmn = pkmn[(pkmn.Type_1=='Water')|(pkmn.Type_2=='Water')] #filtrando apenas linhas com algumas condições\n",
    "water_pkmn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vXlgfodI7Wu"
   },
   "source": [
    "#### Exercício 3.4\n",
    "Siga as instruções e substitua os \\____ para exercitar o que aprendemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEfZ-5seI7Wu"
   },
   "outputs": [],
   "source": [
    "# mostre as 5 primeiras linhas das colunas player_name, position and nationality\n",
    "fut_players[[____]]._____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aukfkphDI7Wx"
   },
   "outputs": [],
   "source": [
    "#renomeie as colunas player_id, player_name and player_extended_name para id, name and extended_name, respectivamente\n",
    "fut_players.____(\n",
    "    columns={____},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "fut_players.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZMmFGoPmI7Wy"
   },
   "outputs": [],
   "source": [
    "#imprima a coluna extended_name do 4534º jogador usando loc e iloc\n",
    "print(fut_players.iloc[____])\n",
    "print(fut_players.loc[____])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxQnswwwI7W0"
   },
   "outputs": [],
   "source": [
    "#nosso DataFrame tem muitas colunas\n",
    "#crie outro DataFrame (fut_players_2) apenas com as colunas na lista abaixo\n",
    "selected_columns = ['id', 'name', 'overall', 'nationality', 'position', 'pref_foot', 'base_id']\n",
    "\n",
    "fut_players_2 = ____\n",
    "\n",
    "fut_players_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9qX4qAmI7W2"
   },
   "outputs": [],
   "source": [
    "#queremos ver os melhores jogadores nascidos no Brasil (Brazil), isto é, aqueles com médio (overall) acima de 90\n",
    "#mostre os 15 primeiros\n",
    "aux_1 = fut_players_2[____]\n",
    "aux_1.____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlSiit9ZI7W5"
   },
   "outputs": [],
   "source": [
    "#vários jogadores bons!\n",
    "#agora mostre os jogadores brasileiros que sejam canhotos (pref_foot é Left) ou que sejam goleiros (position é GK)\n",
    "aux_2 = fut_players_2[____]\n",
    "aux_2.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOgvn0beI7W7"
   },
   "source": [
    "### 3.4 Juntando DataFrames\n",
    "\n",
    "É muito comum ter a necessidade de juntar *DataFrames* diferentes. Se você já utilizou SQL ou qualquer outro banco de dados relacional, deve conhecer isso como *join*. O Pandas também tem a mesma função utilizando o método *.merge()*. Antes do exemplo, vamos relembrar os tipos de *joins* mais comuns:<br>\n",
    "![Joining Methods](https://arquivo.devmedia.com.br/artigos/Fernanda_sallai/sql_join/image001.jpg) <br>\n",
    "Agora, vamos testar os *merge* nos *DataFrames* filtrados que criamos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFNPyF1tI7W7"
   },
   "outputs": [],
   "source": [
    "all_stats = pd.merge(\n",
    "    offensive_stats, #o DataDrame da esquerda\n",
    "    defensive_stats, #o DataDrame da direita\n",
    "    how='inner', #o tipo de join que queremos fazer\n",
    "    on=['#','Name']) #baseado em quais valores em comum\n",
    "all_stats.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UkN4R245I7W9"
   },
   "source": [
    "Ótimo! Conseguimos fazer o *merge* (termo mais utilizado no Pandas) de dois *DataDrames*. Lembre-se que *inner*, *left*, *right* e *outer* terão resultados diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ld4uXURbI7W9"
   },
   "outputs": [],
   "source": [
    "fire_pkmn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Muh-f8YSI7XA"
   },
   "outputs": [],
   "source": [
    "water_pkmn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6TsQX-9I7XC"
   },
   "outputs": [],
   "source": [
    "left_fire_water = pd.merge(fire_pkmn, water_pkmn, how='left', on=['#','Name'])\n",
    "left_fire_water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8s6GHNt9I7XD"
   },
   "outputs": [],
   "source": [
    "right_fire_water = pd.merge(fire_pkmn, water_pkmn, how='right', on=['#','Name'])\n",
    "right_fire_water.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ut5OGXwLI7XF"
   },
   "outputs": [],
   "source": [
    "inner_fire_water = pd.merge(fire_pkmn, water_pkmn, how='inner', on=['#','Name'])\n",
    "inner_fire_water.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0MjzO2AI7XH"
   },
   "source": [
    "Como podemos ver, os resultados são de fato bem diferentes.<br>\n",
    "Podemos também querer apenas concatenar dois *DataDrames*, isto é, juntá-los colocando um abaixo ou ao lado do outro. Para isso, utilizamos o método *.concat()*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aju5mU6hI7XH"
   },
   "outputs": [],
   "source": [
    "fire_and_water = pd.concat([fire_pkmn, water_pkmn], ignore_index=True)\n",
    "fire_and_water.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIZ2uxCfI7XI"
   },
   "source": [
    "Acima fizemos a concatenação vertical. Vamos fazer a horizontal abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8rmU8ZBI7XJ"
   },
   "outputs": [],
   "source": [
    "atk_and_defense = pd.concat([offensive_stats, defensive_stats], axis=1)\n",
    "atk_and_defense.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzPsK8TDI7XK"
   },
   "source": [
    "#### Exercício 3.5\n",
    "Mais uma vez, substitua os \\____ de acordo com as instruções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8HLaE17I7XK"
   },
   "outputs": [],
   "source": [
    "#the_best é um DataDrame dos melhores jogadores em drible (dribbling) e chute (shooting)\n",
    "the_best = fut_players[(fut_players.dribbling > 90) & (fut_players.shooting > 90)][['id', 'name', 'position', 'dribbling', 'shooting', 'overall']]\n",
    "\n",
    "#nationalities é um DataDrame da nacionalidade dos jogadores\n",
    "nationalities = fut_players[['id', 'name', 'nationality']]\n",
    "\n",
    "#faça um merge dos dois DataDrames para obter a nacionalidade dos melhores jogadores (dica: chave é o id)\n",
    "the_best_nationality = pd.merge(____)\n",
    "the_best_nationality.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8AoBG2uI7XM"
   },
   "source": [
    "### 3.5 Operações em grupo\n",
    "\n",
    "Com Pandas nós podemos aplicar operações em grupos usando o método *.groupby()*. Ele é muito útil por ser uma forma bem simples de extrair informação de dados agregados. Para utilizá-lo, passamos as colunas nas quais queremos agrupar os dados e a operação que queremos fazer. Para exemplificar, vamos ver quantos Pokémons lendários cada geração tem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LM1LUqfI7XM"
   },
   "outputs": [],
   "source": [
    "pkmn.groupby('Generation').Legendary.sum() #fazendo uma soma pois a coluna Legendary é boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6-GqOx3I7XO"
   },
   "source": [
    "Podemos obter um relatório da média de diversas colunas para cada tipo de Pokémon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCOLvEygI7XO"
   },
   "outputs": [],
   "source": [
    "pkmn.groupby('Type_1')[['HP','Attack','Defense','Sp_Atk','Sp_Def','Speed']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiyLWKjGI7XP"
   },
   "source": [
    "Isso é realmente muito importante e extremamente utilizado com pandas pois conseguimos fazer análises dos grupos com apenas uma linha de código. Podemos perceber, por exemplo, que Pokémons do tipo *Flying* são especialistas em velocidade enquanto *Dragon* e *Fighting* são especialistas em ataque.\n",
    "\n",
    "#### Exercício 3.6\n",
    "Use o método *.groupby()* para descobrir qual país tem o melhor *overall* médio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y45dj9wlI7XP"
   },
   "outputs": [],
   "source": [
    "#cria o DataDrame country_avg_overall, que tem o overall médio de cada país (nationality), usando groupby\n",
    "country_avg_overall = fut_players.groupby(____).____\n",
    "\n",
    "#usamos o método idxmax() para encontrar o maior overall médio\n",
    "print(\"Melhor overall médio: \\n\", country_avg_overall.loc[country_avg_overall.idxmax()])\n",
    "print(\"Overall médio do Brasil: \", country_avg_overall.loc[\"Brazil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvdzWKOBI7XQ"
   },
   "source": [
    "### 3.6 Aplicando funções no Pandas\n",
    "\n",
    "Com Pandas, nós temos um grande nível de controle de nossos dados, e somos capazes de transformá-los conforme queiramos. Nós podemos, até mesmo, executar funções em DataFrames e manipulá-lo como quisermos. Vamos revisitar o método info()\n",
    "With Pandas, we have a deep level of control of our data, and are able to transform it as we like. We can even perform functions over the DataFrame and manipulate it as we like. Let's revisit the head() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gy91k6dQI7XQ"
   },
   "outputs": [],
   "source": [
    "pkmn.head(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBZGxgGTI7XR"
   },
   "source": [
    "Existem algumas mega evoluções misturadas no dataset. Não seria legal se nós tivéssemos alguma flag que nos diria se um pokémon é mega ou não? E, por um acaso, será que os pokémons mega são mais poderosos?\n",
    "\n",
    "Você deve ter percebido que evoluções mega têm um padrão em nosso DataFrame, algo como 'PokemonMega Pokemon'. Se nós tivermos esse padrão, podemos construir uma função que retorna True is este padrão for detectado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D79vgBfSI7XS"
   },
   "outputs": [],
   "source": [
    "def is_it_mega(pokemon_name):\n",
    "    \"\"\"\n",
    "    Recebe um nome de pokemon e diz se é uma mega evolução ou não\n",
    "    I: string pokemon_name\n",
    "    O: boolean para Mega evos\n",
    "    \"\"\"\n",
    "    if 'Mega ' in pokemon_name: #é importante usar 'Mega ' e não 'mega', pois há um pokemon chamado called Yanmega e outro chamado Meganium que não são uma mega evolução\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3uv8w5mI7XT"
   },
   "source": [
    "Vamos ver se funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5oy-V3fI7XT"
   },
   "outputs": [],
   "source": [
    "is_it_mega('VenusaurMega Venusaur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2vIYa_9I7XV"
   },
   "outputs": [],
   "source": [
    "is_it_mega('Squirtle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NjQh6saI7XW"
   },
   "source": [
    "Excelente! Seria ótimo se conseguíssemos aplicar essa função em todo nosso DataFrame. Para fazer isso, usaremos o método .apply(). Também criaremos uma coluna que é uma flag se o pokémon é mega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SM50UKunI7XW"
   },
   "outputs": [],
   "source": [
    "pkmn['Mega'] = pkmn.apply(\n",
    "    lambda row: is_it_mega(row['Name']), #chamando uma função lambda que acabamos de construir\n",
    "    axis=1 #qual direção queremos executar a função. 0 para horizontal, 1 para vertical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HoAA7rmyI7XX"
   },
   "outputs": [],
   "source": [
    "pkmn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOjBnx2SI7XZ"
   },
   "source": [
    "Agora, vamos verificar quão poderosos são os pokémons mega:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1038lMSmI7XZ"
   },
   "outputs": [],
   "source": [
    "pkmn.groupby('Mega').Total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lodu0N3TI7Xb"
   },
   "source": [
    "Uau! Eles têm quase 200 stat points a mais que pokémons normais! Evoluções mega são, sim, muito poderosos! Uma boa prática é sempre tentar manter nosso DataFrame organizado. A forma como os pokémons mega estão nomeados não é muito ótima, e nós já temos uma coluna com a flag para pokémons Mega, então, vamos atacar isso! A estrutura do nome de um pokémon mega é da seguinte forma: 'NomeMega Nome'. Portanto, se nós pegarmos o qeu vem após o caractere ' ', teremos o nome original do pokémon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsYCr9I_I7Xb"
   },
   "outputs": [],
   "source": [
    "pkmn.Name.nunique() #counts unique elements in a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-ieFrfFI7Xd"
   },
   "outputs": [],
   "source": [
    "def get_original_name(s):\n",
    "    \"\"\"\n",
    "    Recebe um nome de pokemon e retorna seu nome original\n",
    "    I: s string\n",
    "    O: string\n",
    "    \"\"\"\n",
    "    return s.split(' ')[-1]\n",
    "\n",
    "pkmn['Name'] = pkmn.Name.apply(lambda s: get_original_name(s)) #sobreescrevendo a coluna Name\n",
    "pkmn.Name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMxEl2VvI7Xe"
   },
   "outputs": [],
   "source": [
    "pkmn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThDV5uypI7Xf"
   },
   "source": [
    "Parece que conseguimos limpar o nome deles! Agora nós cobrimos todas a parte básica de Pandas! Vamos praticar essa última parte!\n",
    "\n",
    "#### Exercício 3.7\n",
    "Crie uma função que retorna a classificação para o jogador de acordo com as instruções abaixo, então aplique isso para o dataframe fut_players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhsm8yTlI7Xg"
   },
   "outputs": [],
   "source": [
    "def get_classification(overall):\n",
    "    \"\"\"\n",
    "    Recebe um overall de algum jogador e retorna a classificação conforme a seguir:\n",
    "    Overall -> classification\n",
    "    -50     -> \"Amador\"\n",
    "    50-60   -> \"Ruim\"\n",
    "    60-70   -> \"Ok\"\n",
    "    70-80   -> \"Bom\"\n",
    "    80-90   -> \"Ótimo\"\n",
    "    90+     -> \"Lenda\"\n",
    "    \n",
    "    I: int overall\n",
    "    O: string\n",
    "    \"\"\"\n",
    "    ____\n",
    "    \n",
    "fut_players[\"classification\"] = ____\n",
    "fut_players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vGlLn0hI7Xh"
   },
   "source": [
    "<a id=\"encerramento\"></a>\n",
    "# 4. Encerramento\n",
    "\n",
    "Obrigado por participar da trilha, você acaba de finalizar a primeira aula. Neste momento você já deve ser capaz de manipular seus dados no Python, utilizando as bibliotecas que acabamos de aprender! \n",
    "\n",
    "Lembre-se que sempre que surgir alguma dúvida, você pode olhar a documentação do [Numpy](https://numpy.org/doc/) e do [Pandas](https://pandas.pydata.org/docs/).\n",
    "\n",
    "Na próxima aula vamos aprofundar um pouco mais nas visualizações iniciais dos nossos dados, com a parte de EDA (Exploratory Data Analysis) e também veremos o primeiro tipo de algoritmo de ML (Aprendizado Não Supervisionado)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "1.2.NumPy_Pandas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
