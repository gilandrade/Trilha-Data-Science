{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3-final"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":true,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"207px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Aula_5_Séries_Temporais.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yU3OiZ77lIqq"},"source":["# <center>Trilha de Data Science - Amigos da Poli</center>\n","# <center>Séries Temporais</center>\n","___"]},{"cell_type":"markdown","metadata":{"id":"KF-wok70JBf0"},"source":["<a id=\"dsprecap\"></a>\n","## Data Science Pipeline (DSP) recap\n","1. Definição do Problema / Definição do Escopo\n","2. Definição das Métricas de Sucesso\n","3. Definição dos Dados Necessários\n","4. Aquisição de Dados\n","5. Pré-processamento de Dados\n","6. Análise Exploratória de Dados (E.D.A.)\n","7. <i>Feature Engineering</i>\n","8. Construção e Avaliação do Modelo\n","9. Comunicação dos Resultados\n","10. Implantação\n","11. Monitoramento e Manutenção\n","\n","**Essa aula tratará principalmente do passo 8, para os casos de modelos de séries temporais.**"]},{"cell_type":"markdown","metadata":{"id":"SKIz9cN-lIqt"},"source":["<a id=\"intro\"></a>\n","## 1. Introdução"]},{"cell_type":"markdown","metadata":{"id":"mPiNLq8elIqx"},"source":["Diferentemente dos modelos de classificação e regressão que vimos anteriormente, em um problema de série temporal, nosso objetivo é prever os resultados ao longo do tempo. Portanto, há diferenças na maneira como treinamos nosso modelo, onde próprio tempo pode explicar parcialmente o comportamento da variável objetivo.\n","\n","Existem algumas maneiras pelas quais as variáveis ​​podem exibir padrões ao longo do tempo:\n","\n","**Autocorrelação:** pode ser definida como a semelhança entre as observações do conjunto de dados em relação aos períodos de tempo entre eles. Basicamente, é a correlação entre conjuntos da mesma variável sobrepostos em diferentes períodos de tempo.\n","\n","**Sazonalidade:** refere-se a flutuações periódicas. Ele pode ser identificado por meio de funções de autocorrelação. Por exemplo, o consumo de eletricidade é alto durante o dia e baixo durante a noite, ou as vendas online aumentam durante o Natal antes de desacelerar novamente.\n","\n","**Estacionariedade:** é uma característica importante das séries temporais, que se diz estacionária quando suas propriedades estatísticas são estáveis. Isso significa que sua média e variância são constantes e sua covariância é independente do tempo. Isso não é verdade, por exemplo, para variáveis ​​que mudam tendências globais. Tomemos, por exemplo, o preço dos alimentos: na medida em que a inflação incorpora a depreciação da moeda, o preço dos produtos tende a subir em média.\n"]},{"cell_type":"markdown","metadata":{"id":"MNZph7BllIqy"},"source":["<a id=\"ts_pandas\"></a>\n","## 2. Séries Temporais e Pandas"]},{"cell_type":"markdown","metadata":{"id":"agDuv2C6lIqz"},"source":["Neste capítulo vamos fazer algumas análises e manipulações de séries temporais. Para isso, usaremos novamente a biblioteca Pandas.\n","\n","### 2.1. Leitura e visualização inicial\n","\n","Primeiro, temos que dizer ao Pandas que estamos de fato trabalhando com séries temporais. Para fazer isso, precisamos definir o índice DataFrame para uma coluna de data. Abaixo, temos duas maneiras diferentes de fazer isso lendo os dados de uma série temporal de um csv.\n","\n","Para esta primeira parte da aula, vamos usar a série histórica do preço de fechamento das ações do Google, que pode ser encontrada abaixo:\n","\n","- [Conjunto de dados de preços de ações do Google] (https://drive.google.com/file/d/1HebDtFl-1yDgRqGe_O2BHI0q2jYsVk7B/view?usp=sharing)"]},{"cell_type":"code","metadata":{"id":"tFs1NtlslIq0"},"source":["# importando pacotes\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNJ-eDatlIq6"},"source":["# carrega dados da série histórica do csv\n","google = pd.read_csv('.data/GOOG.csv')\n","\n","# transforma coluna Data para datetime, de modo que o Pandas possa reconhecê-la\n","google.Date = pd.to_datetime(google.Date)\n","\n","# define coluna Date como indice\n","google.set_index('Date', inplace=True)\n","google.info()\n","google.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"voLUYDnVlIq_"},"source":["Como você pode ver, o DataFrame tem um DatetimeIndex, de 10/07/2014 a 09/07/2019, e isso é o suficiente para o Pandas entender que estamos lidando com séries temporais. Na verdade, cada coluna pode ser considerada uma série temporal; elas apenas estão no mesmo DataFrame com um índice comum.\n","\n","Abaixo temos a segunda forma de ler os dados do TS, agora diretamente no método ```.read_csv ()```."]},{"cell_type":"code","metadata":{"id":"asLHwuEdlIrA"},"source":["# lê o csv indicando que a coluna Date deve ser carregada com tipo data e usada como índice\n","google = pd.read_csv('data/GOOG.csv', parse_dates=['Date'], index_col='Date')\n","google.info()\n","google.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMjC3JMblIrE"},"source":["Como você pode ver, obtivemos os mesmos resultados fazendo isso em apenas uma linha de código.\n","\n","Agora vamos tentar ver nossos dados. É muito simples fazer isso agora, basta chamar o método plot diretamente no DataFrame."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6bLuwBBblIrF"},"source":["# plota duas séries temporias em mesmo plot\n","google[['Close', 'Volume']].plot(title='Google Open/Close Stock Price')\n","\n","# plota duas séries temporais em plots distintos\n","google[['Close', 'Volume']].plot(title='Google Open/Close Stock Price', subplots=True)\n","\n","# imprime plots\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ner3if7vlIrK"},"source":["Traçar duas séries no mesmo gráfico pode ser ruim se as duas séries têm magnitude diferente, como aconteceu no primeiro caso. A coluna Close acaba sendo uma linha reta já que o Volume é muito maior. Por causa disso, podemos separar os dois apenas adicionando o parâmetro ```subplots = True``` à instrução plot."]},{"cell_type":"markdown","metadata":{"id":"yK6HMj0YlIrL"},"source":["### 2.2. Frequências\n","\n","Uma coisa importante sobre as séries temporais é a frequência. É o que define o intervalo de tempo entre dois registros consecutivos de uma série temporal. Ao definir uma frequência, o pandas cria todas as datas que correspondem a essa frequência no intervalo de seus dados. As frequências podem ser:\n","- H para Horário\n","- D para Diário\n","- B para Dias Úteis\n","- W para Semanal\n","- M para Mensal\n","- Q para Trimestral\n","- A para Anual\n","\n","Vamos ver como isso funciona."]},{"cell_type":"code","metadata":{"id":"8icRIP7RlIrM"},"source":["# define frequência diária\n","google_daily = google[['Close']].asfreq('D')\n","google_daily.info()\n","google_daily.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dp31LtcAlIrR"},"source":["Como você pode ver, 12-07-2014 e 13-07-2014 foram inseridos para ter todos os dias, já que definimos a frequência para diário. Mas isso foi sábado e sexta-feira, então não há informações de bolsa para esses dias. Na verdade, existem quase 600 observações nulas por causa disso. Sabendo disso, é melhor usarmos a frequência dos dias úteis. Apenas por curiosidade, vamos ver como é a frequência anual."]},{"cell_type":"code","metadata":{"id":"v-rfr8DRlIrS"},"source":["# define frequência de dias uteis\n","google_bdaily = google[['Close']].asfreq('B')\n","google_bdaily.info()\n","\n","# define frequencia anual\n","google_annually = google[['Close']].asfreq('A')\n","print(google_annually.head())\n","\n","# define frequencia anual com preenchimento com ultimo valor nulo\n","google_annually_ffill = google[['Close']].asfreq('A', method='ffill')\n","print(google_annually_ffill.head())\n","\n","# define frequencia anual com preenchimento com zeros\n","google_annually_fvalue = google[['Close']].asfreq('A', fill_value=0)\n","print(google_annually_fvalue.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0PUhDsTlIrW"},"source":["Como pudemos ver, a frequência de dias úteis deixou cerca de 50 valores nulos que devem estar relacionados a feriados.\n","\n","No caso de frequência anual, podemos ver que por padrão obtém o último dia de cada, gerando também alguns valores nulos. Mas podemos definir o atributo ```method``` para preencher os NAs com o último valor não nulo com `'ffill'` ou com o próximo valor não nulo com `'bfill'`. Se você quiser preencher com um valor, passe-o para ```fill_value``` como fizemos."]},{"cell_type":"markdown","metadata":{"id":"8PLLxdaPlIrX"},"source":["### 2.3. Interpolação\n","\n","Como acabamos de ver, a mudança de frequências produz alguns NAs para os dados, uma vez que cria observações para alguns dias que não tinham valores anteriormente.\n","\n","Também aprendemos que podemos usar os parâmetros ```fill_value``` e ``` method``` do método ```.asfreq ()``` para imputar um valor fixo ou o último/próximo valor não nulo aos NAs, respectivamente.\n","\n","Outra coisa que podemos fazer para lidar com os NAs é interpolar. Basicamente, o que interpolar faz é fornecer valores para NAs seguindo uma regra e usando os valores não nulos mais próximos antes e depois de NA.\n","\n","Por exemplo, digamos que temos esta lista com quatro valores: \\[2, NA, NA 8 \\]. Podemos substituir esses NAs interpolando-os pela regra *linear*, ou seja, assumindo que todos os valores seguem uma linha de 2 a 8. Com isso, terminamos com a lista \\[2, 4, 6, 8 \\].\n","\n","Chamamos essa *regra* de ```method```, que é um parâmetro para ``` .interpolate () ```, que usamos na célula abaixo. Você pode ver todos os métodos disponíveis na [documentação] (https://pandas.pydata.org/pandas-doc/stable/reference/api/pandas.Series.interpolate.html)."]},{"cell_type":"code","metadata":{"id":"3DRXsLIslIrY"},"source":["# interpolação com método linear\n","google_daily['interpolation_linear'] = google_daily.Close.interpolate(method='linear')\n","\n","# interpolação com método polinomial\n","google_daily['interpolation_poly'] = google_daily.Close.interpolate(method='polynomial', order=3)\n","\n","# imprime resultados\n","google_daily[['Close','interpolation_linear','interpolation_poly']].loc['2019-05'].plot(subplots=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grYwBhNglIrc"},"source":["Como mostra o gráfico, tivemos os NAs na série temporal ```google_daily```. Em seguida, aplicamos interpolar com dois métodos diferentes, o que nos dá duas novas séries ligeiramente diferentes.\n","\n","Não existe uma regra de ouro para escolher o método ao aplicar a interpolação. É importante entender cada método e pensar qual ajustaria melhor seus dados e, acima de tudo, experimentar!"]},{"cell_type":"markdown","metadata":{"id":"KpFgMYr8lIrd"},"source":["### 2.4. Slicing\n","\n","Uma prática muito frequente quando manipulamos dados de séries temporais é o corte do data frame, denominado 'slicing'. Com o Pandas, essa atividade é simplificada, de modo que pode-se simplesmente passar um ano, ano-mês ou intervalo entre colchetes para filtrar os dados. Você ainda pode usar ```.loc[]``` para selecionar uma data específica. Dê uma olhada abaixo.\n"]},{"cell_type":"code","metadata":{"id":"-J_yef_tlIre"},"source":["# copia série\n","google_close = google[['Close']].copy()\n","\n","# seleciona apenas dados de 2015\n","google_close['2015'].plot()\n","\n","# seleciona da dos de março/2016 a fevereiro/2017. Note que é um intervalo fechado (inclusivo nas pontas)\n","google_close['2016-3': '2017-1'].plot()\n","\n","# seleciona dados de uma data específica\n","print(google.loc['2016-6-1', 'Close'])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcQjxqqzlIrj"},"source":["### 2.5. Deslocamento - _Shifting_\n","\n","Frequentemente, ao usar séries temporais, precisamos comparar um valor com outro. Por exemplo: se eu quisesse saber quanto mudou o preço das ações de um dia para o outro? Aqui comumente deslocamos as séries temporais para facilitar a operação.\n","\n","Basicamente, o deslocamento move todos os valores da série temporal em uma direção. Para nosso exemplo, poderíamos deslocar todos os valores em uma posição e, em seguida, usar operações para comparar esses valores. Abaixo, fazemos exatamente isso."]},{"cell_type":"code","metadata":{"id":"sKfeWov1lIrk"},"source":["# move valores um período pra frente\n","google_close['shifted'] = google_close.Close.shift() # default: periods=1\n","\n","google_close.head(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QW7rwBPdlIro"},"source":["Como você pode ver, o primeiro valor dos dados deslocados é NaN, pois não havia nenhum registro anterior para ser colocado naquele local. E se quiséssemos deslocar para outra direção?"]},{"cell_type":"code","metadata":{"id":"JbJbNnmXlIrp"},"source":["# move valores um período para trás \n","google_close['lagged'] = google_close.Close.shift(periods=-1)\n","\n","google_close.tail(3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"en0Xv48llIrt"},"source":["Mais uma vez, o último valor dos dados defasados é NaN porque não houve registros depois disso.\n","\n","Agora podemos calcular a mudança entre um dia e outro com os dados deslocados."]},{"cell_type":"code","metadata":{"id":"_aJo9OmHlIru"},"source":["# divide preço de fechamento pela coluna deslocada para obter a variação\n","google_close['change'] = google_close.Close.div(google_close.shifted)\n","\n","# subtrai 1 e multiplica por 100 para obter retorno percentual\n","google_close['return'] = google_close.change.sub(1).mul(100)\n","\n","google_close.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yGHOnC3TlIrz"},"source":["Fácil, não é? Na verdade, para diferença e mudança percentual, existem métodos predefinidos. Você só precisa passar por quantos períodos deseja que seus dados sejam deslocados. Dê uma olhada abaixo."]},{"cell_type":"code","metadata":{"id":"HlXBn0VTlIr0"},"source":["# diferença absoluta entre dois dias adjacentes\n","google_close['diff'] = google_close.Close.diff()\n","\n","# diferença absoluta para dois dias com distancia de 3 dias entre si\n","google_close['diff_3d'] = google_close.Close.diff(3)\n","\n","# variação percentual entre dois dias adjacentes\n","google_close['pct_change'] = google_close.Close.pct_change().mul(100)\n","\n","# variação percentual para dois dias com distancia de 3 dias entre si\n","google_close['return_3d'] = google_close.Close.pct_change(3).mul(100)\n","\n","google_close[['Close', 'diff', 'diff_3d', 'return', 'pct_change', 'return_3d']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xSfsxi3alIr4"},"source":["Resample altera a frequência de seus dados para uma frequência inferior (downsampling) ou superior (upsampling). Upsampling não é muito comum e geralmente envolve interpolação ou outros métodos de preenchimento. Aqui, vamos nos concentrar na redução da resolução que é comumente usada com alguma função de agregação, como um agrupamento para uma série temporal.\n","\n","O que acontece é que você passa uma frequência para o método ```.resample ()``` e ele agrupa todos os valores naquele novo período, então você pode aplicar uma função a ele, criando um único valor a partir deles. Isso geralmente é usado para fazer uma versão mais suave de sua série. Algumas frequências que aceitam resampling são:\n","- M por mês\n","- MS para início do mês\n","- BM para o mês comercial\n","- BMS para início do mês comercial\n","\n","Veja a seguir onde calculamos a mediana de um período da semana e a média de um período que começa no primeiro dia útil do mês."]},{"cell_type":"code","metadata":{"id":"xbXrj5bglIr4"},"source":["# apenas dados de 2018\n","google_18 = google[['Close']]['2018']\n","\n","# plot\n","axes = google_18.plot()\n","\n","# aplica média e mediana\n","monthly_mean = google_18.resample('W').median().add_suffix('_weekly_median')\n","monthly_median = google_18.resample('BMS').mean().add_suffix('_monthly_mean')\n","\n","# plota no mesmo eixo\n","monthly_mean.plot(ax=axes)\n","monthly_median.plot(ax=axes)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eVMxQY5DlIr_"},"source":["### 2.6. Funções de Janela - _Window Functions_\n","\n","A função de janela é uma funcionalidade muito útil ao trabalhar com séries temporais. Basicamente, o que ele faz é, para cada registro da série temporal:\n","- 1. definir o registro como referência\n","- 2. identificar um subperíodo da série temporal (janela)\n","- 3. calcular métricas para a janela\n","- 4. criar uma nova série temporal das métricas\n","\n","Com isso, existem dois tipos de janelas:\n","- Janelas Rolantes - _Rolling Window_: janela de tamanho fixo do registro atual que 'rola' conforme a referência muda\n","- Janelas de Expansão - _Expanding Window_: a janela contém todos os registros até a referência\n","\n","A ideia é semelhante à redução da resolução, com a diferença de que nas funções de janela um registro pode aparecer em várias janelas (dependendo do tamanho da janela), enquanto na redução da resolução, cada registro aparece em um e apenas um compartimento, pois não há referência móvel na redução da resolução."]},{"cell_type":"markdown","metadata":{"id":"kYkoJegf6LG_"},"source":["#### 2.6.1. Janelas Rolantes - _Rolling Windows_\n","As janelas rolantes (ou deslizantes) aplicam uma função a uma janela que desliza pela série. A imagem abaixo mostra uma visualização de como funciona uma janela deslizante, onde a cada iteração uma parte da série temporal é coberta pela janela. \n","\n","![rolling_window](https://docs.wavefront.com/images/5sec_moving_window.png)\n","\n","Imagine que a cada iteração, uma operação é feita sobre a janela, como por exemplo o cálculo da média.\n","\n","\n","Vamos entender como isso é feito na prática. Para cada observação, calcularemos o valor médio das últimas 3 observações e também, separadamente, o valor médio dos últimos 3 dias."]},{"cell_type":"code","metadata":{"id":"IQuUIKJklIsA"},"source":["obs_window = google.Close.rolling(window=3).mean() # número fixo de observações (janela de observação)\n","\n","period_window = google.Close.rolling(window='3D').mean() # período fixo (janela de período)\n","\n","window = pd.concat([google.Close, obs_window.to_frame().add_suffix('_obs_mean'), period_window.to_frame().add_suffix('_per_mean')], axis=1)\n","window.info()\n","window.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b3ILUuqDlIsE"},"source":["Como podemos ver, o uso da janela de observação produz NAs até que tenhamos pelo menos o tamanho da janela para aplicar a média, enquanto a janela do período se ajusta até ter a janela do buraco para calcular a média.\n","\n","Pode-se notar que existem algumas observações que possuem os mesmos valores para ```Close_obs_mean``` e ``` Close_per_mean``` e outras que não. A razão para isso são os dias sem informações de fechamento, já que a janela de observação pula esses dias enquanto a janela de período os conta. Portanto, se não houver dias sem negociação (finais de semana ou feriados) na janela do período, os dois valores serão iguais.\n","\n","Podemos calcular múltiplas métricas com a mesma janela rolante usando ```agg``` ou armazenando a janela rolante em uma variável e usando-a várias vezes. Mostramos os duas formas:"]},{"cell_type":"code","metadata":{"id":"aMYTt_ZtlIsF"},"source":["# Método 1\n","r = google.Close.rolling('90D').agg(['mean', 'std'])    # calculo de média e desvio padrao\n","r.plot(subplots = True)                                 # plot separadamente\n","\n","# Método 2\n","rolling = google.Close.rolling('360D')                  # armazena janela em variavel\n","q10 = rolling.quantile(.1).to_frame('q10')              # calculo do 10 quartil (q10)\n","median = rolling.median().to_frame('median')            # cálculo da mediana\n","q90 = rolling.quantile(.9).to_frame('q90')              # calculo do 90 quartil (q90)\n","pd.concat([q10, median, q90], axis=1).plot()            # plot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PUaHBiBzlIsJ"},"source":["#### 2.6.2. Janelas de Expansão - _Expanding Windows_\n","\n","As janelas de expansão levam todas as observações até a referência para calcular as métricas. Funciona com o método ```expanding``` que é semelhante ao ```rolling```, mas não precisa do tamanho da janela. \n","\n","Abaixo, usamos a janela de expansão para somar os valores em um DataFrame com dados inteiros de 1 a 10. Observe que fazemos isso de duas formas: com o método de expansão e com ```.cumsum()``` que serve como o agregação de ```.expanding()``` e ```.sum()```. Também temos ```.cumprod()```, ```.cummin()``` e ```.cummax()``` que seguem a mesma idéia."]},{"cell_type":"code","metadata":{"id":"z0A1l9EIlIsJ"},"source":["df = pd.DataFrame({'data': range(1, 11)})          # cria dataframe\n","df['expanding sum'] = df.data.expanding().sum()    # expanding()\n","df['cumulative sum'] = df.data.cumsum()            # cumsum()\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T8ZmWLrMlIsN"},"source":["Em outro exemplo, podemos calcular os valores máximo e mínimo para o preço das ações do Google até esse ponto, como fazemos abaixo."]},{"cell_type":"code","metadata":{"id":"a6TO0IpNlIsO"},"source":["google['running_min'] = google.Close.expanding().min()\n","google['running_max'] = google.Close.expanding().max()\n","google[['Close', 'running_min', 'running_max']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iu1DJrjhlIsS"},"source":["## 3. Divisão de treino/validação/teste\n","Embora esta seção já tenha sido apresentada nas duas últimas lições, aqui apresentamos algumas novas ideias para que possamos explicar a influência do tempo nas divisões de sets de treino, validação e teste.\n"]},{"cell_type":"markdown","metadata":{"id":"_IpLHA5U6Xbc"},"source":["### 3.1. Divisão Temporal\n","O impacto do tempo no comportamento dos dados é algo que devemos considerar para cada modelo, portanto, podemos (e devemos) aplicar o que discutiremos aqui aos problemas de classificação e regressão também. Só deixamos essa discussão para esta aula porque as séries temporais, como o nome diz, exibem comportamentos influenciados pelo tempo.\n","\n","O principal problema com a divisão treino/teste que usamos antes é que ela é aleatória. Isso significa que escolhemos aleatoriamente um subconjunto de nossos dados para treinar e outro no qual testamos nosso modelo. Este método é baseado em uma forte suposição de que as observações são independentes entre si, o que significa que o resultado de uma observação não está correlacionado ao resultado de outras.\n","\n","Mas ao usar a série temporal, isso deixa de ser verdade. Por exemplo, pegue o último gráfico que fizemos na seção anterior e tente informar o preço das ações do Google em 17/10/2018. Você não pode dizer o valor exato porque o gráfico é muito pequeno, mas o que você pode dizer é que está mais próximo de 1100 do que de 600 apenas porque o valor médio para o final de 2018 está em torno de 1100, enquanto o valor 600 não acontecia desde 2015. Os valores dos dados das séries temporais tendem a estar mais próximos dos valores das observações próximas em termos de tempo.\n","\n","Nesse caso, usando a divisão aleatória, quando o modelo tenta prever uma observação de 2017 no conjunto de teste, ele teria uma estimativa melhor enviesada, pois viu os dados de 2014 a 2019 no conjunto de treinamento e os usou como uma pista, ficando boas as métricas de acurácia para esse modelo. Quando então colocamos esse modelo em produção, ele não terá mais essa pista, tornando a previsão mais difícil e as métricas de acurácia piores.\n","\n","É por isso que devemos usar uma divisão temporal nos dados para criar os conjuntos de treino e teste. Escolhemos uma data de referência e usamos as observações antes disso para treinar e depois disso para testar. Fazendo isso, podemos assegurar que o modelo nunca viu no treinamento uma observação que ocorre depois daquela com que está sendo testado, como acontecerá na vida real."]},{"cell_type":"code","metadata":{"id":"qabjWWoElIsS"},"source":["train = google[:'2018-12']\n","test = google['2019-01':]\n","\n","pd.concat([train.add_suffix('_train').Close_train, test.add_suffix('_test').Close_test], axis=1, sort=False).plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vnyMqxQ1lIsW"},"source":["### 3.2. Validação Cruzada - _Cross Validation_\n","\n","Assim que tivermos nosso conjunto de teste, precisamos usar um conjunto de validação ou validação cruzada para fazer o ajuste de hiperparâmetros, como fizemos em outras lições. <br>\n","No caso de um conjunto de validação, só precisamos dividir os dados temporariamente mais uma vez. <br>\n","Quando falamos sobre validação cruzada, na verdade temos dois métodos, assim como vimos nas funções de janela: rolar ou expandir. A ideia é exatamente a mesma, rolando usaremos um teste de tamanho fixo e rolaremos pelos dados, enquanto a expansão usará todos os dados anteriores. A imagem abaixo deve facilitar o entendimento.\n","\n","![cv_split](https://1fykyq3mdn5r21tpna3wkdyi-wpengine.netdna-ssl.com/wp-content/uploads/2018/09/image6-e1536165830511-696x184.png)\n","\n","Você pode ver como fazer os dois métodos de validação cruzada nas células a seguir."]},{"cell_type":"code","metadata":{"id":"NPLn9GfClIsX"},"source":["# janela rolante\n","# utiliza histórico fixo para treino\n","from sklearn.model_selection import TimeSeriesSplit\n","cv = TimeSeriesSplit(n_splits=10, max_train_size=400)\n","\n","fig, ax = plt.subplots(figsize=(10, 5))\n","for index, (train, test) in enumerate(cv.split(google)):\n","    # Plota índices de treino e teste\n","    l1 = ax.scatter(train, [index] * len(train), c=[plt.cm.coolwarm(.1)], marker='_', lw=6)\n","    l2 = ax.scatter(test, [index] * len(test), c=[plt.cm.coolwarm(.9)], marker='_', lw=6)\n","    ax.set(ylim=[10, -1], title='TimeSeriesSplit behavior', xlabel='data index', ylabel='CV iteration')\n","    ax.legend([l1, l2], ['Training', 'Validation'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"PmiWolO7lIsc"},"source":["# métodp de janela de expansão\n","# using all history to train\n","from sklearn.model_selection import TimeSeriesSplit\n","cv = TimeSeriesSplit(n_splits=10)\n","\n","fig, ax = plt.subplots(figsize=(10, 5))\n","for index, (train, test) in enumerate(cv.split(google)):\n","    # Plota índices de treino e teste\n","    l1 = ax.scatter(train, [index] * len(train), c=[plt.cm.coolwarm(.1)], marker='_', lw=6)\n","    l2 = ax.scatter(test, [index] * len(test), c=[plt.cm.coolwarm(.9)], marker='_', lw=6)\n","    ax.set(ylim=[10, -1], title='TimeSeriesSplit behavior', xlabel='data index', ylabel='CV iteration')\n","    ax.legend([l1, l2], ['Training', 'Validation'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w9HSnmDClIsh"},"source":["O método da janela de expansão é usado com mais frequência, mas pode ser alterado para o método da janela rolante se a quantidade de dados for muito grande, para que o treinamento seja mais rápido."]},{"cell_type":"markdown","metadata":{"id":"NdmcnQ2wlIsi"},"source":["### 3.3 Lembrando: Métricas de Avaliação do Modelo\n","\n","Como você pode imaginar, as métricas para avaliar um modelo de série temporal são diferentes daquelas usadas para avaliar modelos de regressão. Para modelos de série temporal, geralmente usamos uma das seguintes métricas:\n","* MAPE (Mean Absolute Percentage Error)\n","* MAE (Mean Absolute Error)\n","* MSE (Mean Squared Error)\n","* RMSE (Root Mean Squared Error)\n","* R² (R Squared)\n","\n","\n","#### MAE (Mean Absolute Error)\n","\n","MAE é a média da diferença absoluta entre os valores previstos e o valor observado. O MAE é uma pontuação linear, o que significa que todas as diferenças individuais são ponderadas igualmente na média. Por exemplo, a diferença entre 10 e 0 será o dobro da diferença entre 5 e 0. No entanto, o mesmo não é verdade para RMSE, apresentado abaixo. Matematicamente, é calculado usando esta fórmula:\n","\n","![Imgur](https://cdn-images-1.medium.com/max/800/1*8DXbECB9pnKxTpIvuVD-vg.png)\n","\n","\n","#### RMSE (Root Mean Squared Error)\n","\n","RMSE é uma métrica que também mede a magnitude média do erro. Porém, como os erros são elevados ao quadrado antes de serem calculados, o RMSE atribui um peso relativamente alto aos erros maiores. Isso significa que o RMSE é mais útil quando erros grandes (outliers) são particularmente indesejáveis\n","\n","![Imgur](https://cdn-images-1.medium.com/max/1000/1*qz8jRMxmMEwNsFh0Cs5XfQ.png)\n","\n","\n","#### MAPE (Mean Absolute Percentage Error)\n","\n","MAPE é uma medida de erro relativo que usa valores absolutos. O MAPE tem duas vantagens: primeiro, os valores absolutos evitam que os erros positivos e negativos se anulem. Em segundo lugar, como os erros relativos não dependem da escala da variável dependente, essa medida permite comparar a acurácia da previsão entre dados de séries temporais com escalas diferentes. Ele expressa a acurácia como uma porcentagem e é definido pela fórmula:\n","\n","![img](https://help.sap.com/doc/PRODUCTION/1befe448825347d4887fbc24b6d7f3b3/2019.1/en-US/loioeb041bbe0df84947914d58b0c3f60dd7_LowRes.png)\n","\n","Para entender melhor esses conceitos, sugerimos as seguintes leituras:\n","1. [Artigo](https://medium.com/usf-msds/choosing-the-right-metric-for-machine-learning-models-part-1-a99d7d7414e4)\n","2. [Dataquest](https://www.dataquest.io/blog/understanding-regression-error-metrics/)"]},{"cell_type":"markdown","metadata":{"id":"agSMuAL6lIsi"},"source":["## 4. Modelagem"]},{"cell_type":"markdown","metadata":{"id":"x1ocjDuElIsj"},"source":["### 4.1. Métodos Clássicos"]},{"cell_type":"markdown","metadata":{"id":"pn57LeHklIsk"},"source":["Antes de explorar os métodos de aprendizado de máquina para séries temporais, é uma boa ideia garantir que você tenha esgotado os métodos clássicos de previsão de séries temporais lineares. Os métodos clássicos de previsão de séries temporais podem ser focados em relações lineares, no entanto, eles são sofisticados e têm um bom desempenho em uma ampla gama de problemas, assumindo que seus dados estão adequadamente preparados e o método está bem configurado.\n","\n","![img](https://media.giphy.com/media/zZeCRfPyXi9UI/giphy.gif)\n","\n","Os chamados métodos clássicos são as técnicas de previsão baseadas em valores previamente observados, estatísticas significativas e outras características de dados anteriores. Ao contrário das técnicas de aprendizado de máquina, os métodos apresentados a seguir não usam fatores externos para explicar a previsão. Em vez disso, eles identificam padrões nos valores observados, como os componentes apresentados na seção a seguir.\n","\n","Nesta aula, falaremos sobre três dos métodos mais conhecidos de previsão. Embora pareçam simples, eles podem fornecer resultados razoáveis a depender da série temporal em questão.\n","\n","Por último, usaremos a biblioteca `Prophet`, a ferramenta de previsão de código aberto do Facebook disponível em Python e R. Essa ferramenta permite que especialistas e não especialistas produzam previsões com o mínimo de esforço.\n","\n","Mas primeiro vamos preparar nossos dados. Usaremos os dados de preços de fechamento de ações do Google para realizar as previsões."]},{"cell_type":"markdown","metadata":{"id":"NZTmPRNxlIsl"},"source":["#### 4.1.1. Componentes de Séries Temporais"]},{"cell_type":"markdown","metadata":{"id":"VSYYHQLqlIsl"},"source":["As várias razões ou forças que afetam os valores de uma observação em uma série de tempo são os componentes de uma série de tempo. As quatro categorias dos componentes da série temporal são:\n","\n","- Tendência\n","- Sazonalidade\n","- Ciclicidade\n","- Movimentos aleatórios ou irregulares\n","\n","Provavelmente, a melhor maneira de verificar se esses componentes estão afetando a série temporal é __plotando__ os dados históricos"]},{"cell_type":"markdown","metadata":{"id":"Lf_FWZvPlIsm"},"source":["##### Tendência"]},{"cell_type":"markdown","metadata":{"id":"6eWKpdePlIsn"},"source":["Os dados têm uma inclinação consistente para cima ou para baixo?\n","\n","<img src = \"https://i.imgur.com/QnqrSOo.png\" width = 500>"]},{"cell_type":"markdown","metadata":{"id":"1cs9DR5hlIsn"},"source":["##### Sazonalidade"]},{"cell_type":"markdown","metadata":{"id":"xawxhXBSlIso"},"source":["O dado possui algum tipo de padrão sazonal?\n","\n","<img src = \"https://i.imgur.com/Izg45uj.png\" width = 500>"]},{"cell_type":"markdown","metadata":{"id":"eQ2OvuCZlIsp"},"source":["##### Ciclicidade"]},{"cell_type":"markdown","metadata":{"id":"JXoOyNx4lIsp"},"source":["Os dados possuem alguma ciclicidade aperiódica?\n","\n","<img src = \"https://i.imgur.com/fHrJaFl.png\" width = 500>"]},{"cell_type":"markdown","metadata":{"id":"pVc0AGcYlIsq"},"source":["#### 4.1.2. Data Prep"]},{"cell_type":"code","metadata":{"id":"00fpVcMelIsq"},"source":["# visualização inicial dos dados\n","google_daily.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bfbfdPVWlIsu"},"source":["# existem valores faltantes devido a finais de semana e feriados\n","google_bdaily.isnull().values.any()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"uR0eEIk1lIsz"},"source":["# vamos preencher os valores faltantes com registros anteriores, dado que podemos assumir que o preço da ação não muda durante os feriados e finais de semana\n","google_daily_fill = google[['Close']].asfreq('D', method='bfill')\n","google_daily_fill.isnull().values.any()\n","google_daily_fill = google_daily_fill.rename({'Close': 'y'}, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csIhdz8_lIs6"},"source":["# vamos fazer o split entre série de treino e teste\n","train_ts = google_daily_fill[:'2018-12']\n","test_ts = google_daily_fill['2019-01':]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZJV_hD4lIs_"},"source":["# visualização do set de treino\n","train_ts.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OL23WacNlItC"},"source":["#### 4.1.3. Média Móvel"]},{"cell_type":"markdown","metadata":{"id":"oojnDWrNlItD"},"source":["A média móvel é uma das técnicas de previsão mais simples e amplamente utilizada para se ter uma ideia geral das tendências em um conjunto de dados. A média móvel é extremamente útil para __prever tendências de longo prazo__. Por exemplo, os analistas do mercado de ações costumam usar uma média móvel de 50 ou 200 dias para ajudá-los a ver as tendências no mercado de ações e prever para onde as ações estão indo.\n","\n","Vamos a um exemplo:\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"SM8jQKBplItD"},"source":["# média móvel dos últimos 200 dias\n","moving_avg = train_ts.rolling(window=200).mean()\n","plt.plot(train_ts)\n","plt.plot(moving_avg, color='red')\n","plt.plot(test_ts, color='orange')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uCLyKlPGlItH"},"source":["#### 4.1.4. Decomposição Clássica"]},{"cell_type":"markdown","metadata":{"id":"xQnHB5sSlItH"},"source":["A decomposição é usada principalmente para análise de séries temporais e, como uma ferramenta de análise, pode ser usada para informar os modelos de previsão sobre o seu problema.\n","\n","Ele fornece uma maneira estruturada de pensar sobre um problema de previsão de série temporal, geralmente em termos de complexidade de modelagem e, especificamente, em termos de como melhor capturar cada um desses componentes em um determinado modelo.\n","\n","A biblioteca `statsmodels` fornece uma implementação do método de decomposição clássica, em uma função chamada\n","`seasonal_decomposição`. Requer que você especifique se o modelo é aditivo ou multiplicativo."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"zQct90fHlItI"},"source":["from statsmodels.tsa.seasonal import seasonal_decompose\n","\n","# cria modelo\n","decomposition = seasonal_decompose(train_ts, model='multiplicative')\n","\n","# define componentes\n","trend = decomposition.trend\n","seasonal = decomposition.seasonal\n","residual = decomposition.resid\n","\n","# plots\n","plt.subplot(411)\n","plt.plot(train_ts, label='Original')\n","plt.legend(loc='best')\n","\n","plt.subplot(412)\n","plt.plot(trend, label='Trend')\n","plt.legend(loc='best')\n","\n","plt.subplot(413)\n","plt.plot(seasonal, label='Seasonality')\n","plt.legend(loc='best')\n","\n","plt.subplot(414)\n","plt.plot(residual, label='Residuals')\n","plt.legend(loc='best')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4H9pO2pClItM"},"source":["#### 4.1.5. Amortecimento Exponencial"]},{"cell_type":"markdown","metadata":{"id":"EnMmLd5mlItN"},"source":["O amortecimento exponencial é um método de previsão de série temporal para dados univariados que pode ser estendido para dar suporte a dados com uma tendência sistemática ou componente sazonal.\n","\n","> As previsões produzidas usando métodos de amortecimento exponencial são médias ponderadas de observações anteriores, com os pesos decaindo exponencialmente à medida que as observações envelhecem. Em outras palavras, quanto mais recente a observação, maior o peso associado.\n","\n","— Página 171, [Forecasting: principles and practice](https://amzn.to/2xlJsfV), 2013."]},{"cell_type":"code","metadata":{"id":"401P5SVslItO"},"source":["# importa biblioteca\n","from statsmodels.tsa.holtwinters import ExponentialSmoothing\n","\n","# cria classe\n","expsmoothing = ExponentialSmoothing(train_ts)\n","\n","# fit do modelo\n","expsmoothing_fit = expsmoothing.fit()\n","\n","# previsao\n","expsmoothing_yhat = expsmoothing_fit.predict(test_ts.index[0], test_ts.index[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j09Jcs-pK-0p"},"source":["expsmoothing_yhat"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppmh-xfYlItS"},"source":["# plot dos resultados\n","plt.plot(test_ts, color='orange')\n","plt.plot(expsmoothing_yhat, color='red')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-hbB_nGlItW"},"source":["# dataset para medir erro\n","exp_forecast = pd.concat([train_ts.append(test_ts),\n","                          expsmoothing_yhat.rename('yhat')], axis=1, sort=False)\n","\n","exp_forecast.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6it-V2flItb"},"source":["# função reutilizável para cálculo de erros\n","def calculate_forecast_errors(df, prediction_size):\n","    \n","    df = df.copy()\n","    \n","    df['e'] = df['y'] - df['yhat']\n","    df['p'] = 100 * df['e'] / df['y']\n","    \n","    predicted_part = df[-prediction_size:]\n","    \n","    error_mean = lambda error_name: np.mean(np.abs(predicted_part[error_name]))\n","    \n","    return {'MAPE': error_mean('p'), 'MAE': error_mean('e')}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1B6Uj7MlItf"},"source":["# métricas de erro\n","for err_name, err_value in calculate_forecast_errors(exp_forecast, len(test_ts)).items():\n","    print(err_name, err_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLta3s-1lItm"},"source":["#### 4.1.6. ARIMA"]},{"cell_type":"markdown","metadata":{"id":"8qiZZVqBlIto"},"source":["O Autoregressive Integrated Moving Average (ARIMA) modela a previsão como uma função linear das observações diferenciadas e erros residuais em observações anteriores.\n","\n","Ele combina os modelos de Autorregressão (AR) e Média Móvel (MA), bem como uma etapa de pré-processamento de diferenciação da sequência para tornar a sequência estacionária, chamada integração (I)."]},{"cell_type":"code","metadata":{"id":"s0kN_oFHlItq"},"source":["# imports\n","from statsmodels.tsa.arima_model import ARIMA\n","\n","# fit do modelo\n","ar_model = ARIMA(train_ts, order=(1, 1, 1))\n","ar_fit = ar_model.fit(disp=False)\n","\n","# previsão\n","ar_yhat = ar_fit.predict(test_ts.index[0], test_ts.index[-1], typ='levels')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"eRXoSEUilItw"},"source":["# plot results\n","plt.plot(test_ts, color='orange')\n","plt.plot(ar_yhat, color='red')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtapByoYlIt1"},"source":["# dataset para medir erro\n","arima_forecast = pd.concat([train_ts.append(test_ts),\n","                            ar_yhat.rename('yhat')], axis=1, sort=False)\n","\n","arima_forecast.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g4WVbGoLlIt5"},"source":["# métricas de erro\n","for err_name, err_value in calculate_forecast_errors(arima_forecast, len(test_ts)).items():\n","    print(err_name, err_value)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oPPIJY9jlIt8"},"source":["#### 4.1.7. Prophet"]},{"cell_type":"markdown","metadata":{"id":"NrX3wlgjlIt9"},"source":["Como mencionado acima, o Prophet é uma ferramenta que foi construída para lidar com essas questões e fornece uma abordagem prática para previsões “em escala”. Ele pretende automatizar os recursos comuns de séries temporais de negócios, fornecendo métodos simples e ajustáveis. O Prophet permite que os analistas, com uma variedade de experiências, façam mais previsões do que manualmente."]},{"cell_type":"markdown","metadata":{"id":"8JAy9nJclIt-"},"source":["O pacote `Prophet` possui algumas maneiras específicas de lidar com os dados. Por exemplo, os dados de entrada podem ter apenas duas colunas chamadas `ds` e `y`."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"v6CRJBMhlIt_"},"source":["# ajuste do dataset de treino\n","train_prophet = train_ts.reset_index()\n","train_prophet.columns = ['ds', 'y']\n","train_prophet.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnbQAmualIuC"},"source":["# adjust do dataset de teste\n","test_prophet = test_ts.reset_index()\n","test_prophet.columns = ['ds', 'y']\n","test_prophet.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ewyyts40lIuF"},"source":["# imports\n","from fbprophet import Prophet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbt5nB2llIuJ"},"source":["# instancia prophet e treina\n","m = Prophet()\n","m.fit(train_prophet)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djEHYtBBlIuM"},"source":["# construção do dataset de teste para alimentar o modelo\n","future = m.make_future_dataframe(periods=len(test_prophet))\n","\n","# realiza previsão\n","forecast = m.predict(future)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQIQUh3vlIuR"},"source":["# plot dos resultados\n","m.plot(forecast);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3CmV9aVlIuZ"},"source":["# plot das componentes da série\n","m.plot_components(forecast);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"237RvPPllIuc"},"source":["# função para construir dataset com valores históricos e previsão realizada\n","def make_comparison_dataframe(historical, forecast):\n","    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(historical.set_index('ds'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eDFoj79MlIuk"},"source":["# usa função para construir dataset\n","prophet_forecast = make_comparison_dataframe(train_prophet.append(test_prophet), forecast)\n","\n","prophet_forecast.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lLXeKzElIun"},"source":["# cálculo de erros\n","for err_name, err_value in calculate_forecast_errors(prophet_forecast, len(test_ts)).items():\n","    print(err_name, err_value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jro4QcH1lIur"},"source":["# plot dos resultados\n","plt.plot(train_ts)\n","plt.plot(test_ts, color='orange')\n","plt.plot(prophet_forecast['yhat'], color='red')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rC8uVrzlIuu"},"source":["Que modelo você usaria? ARIMA, Amortecimento Exponencial ou os recursos do `Prophet`?"]},{"cell_type":"markdown","metadata":{"id":"f0MbhIg0lIuu"},"source":["### 4.2. Métodos de Machine Learning\n","\n","Até agora, aprendemos como realizar uma previsão apenas analisando os padrões da própria série temporal. No entanto, se a série temporal que você deseja prever é fortemente influenciada por fatores externos (expressos na forma de variaveis causais), você deve utilizar outras técnicas que consigam levar em consideração essas relações de causalidade. Caso você tenha esquecido da diferença entre causalidade e correlação:\n","\n","\n","* **Correlação**: refere-se ao grau de associação entre duas variáveis aleatórias. Portanto, a correlação entre dois conjuntos de dados é o quanto eles se parecem. por exemplo: como o preço da ação de hoje está associada à de ontem?\n","* **Causalidade**: implica que A e B têm uma relação de causa e efeito um com o outro. Você está dizendo que A causa B. Por exemplo: como o crescimento da população afeta o preço da ação do google?"]},{"cell_type":"markdown","metadata":{"id":"BxbupEPClIuv"},"source":["#### 4.2.1. Métodos baseados em árvore\n","\n","Vamos pegar nosso exemplo de conjunto de dados de série temporal para aplicar um modelo de floresta aleatório (Random Forest), assim como fizemos na última aula, e ver como ele funciona."]},{"cell_type":"markdown","metadata":{"id":"pHrp-VhXlIuv"},"source":["Vamos considerar o seguinte problema: você foi convidado por uma empresa de transporte queniana para construir um modelo para prever quantos passageiros vão estar em cada viagem de ônibus com destino a Nairóbi em sua programação.\n","\n","Este é um concurso real de ciência de dados da [Zindi] (https://zindi.africa/competitions/traffic-jam-predicting-peoples-movement-into-nairobi), uma plataforma de competição de ciência de dados com a missão de construir um ecossistema de ciência de dados na África. O dois conjuntos de dados usados neste notebook estão na pasta /data:\n","\n","- [Nairobi Raw] \n","- [Nairóbi Treated]"]},{"cell_type":"markdown","metadata":{"id":"5VuZqWYslIuw"},"source":["O dataset inicial fornecido pela companhia é o seguinte:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"kiAs4t7vlIux"},"source":["# imports de blibliotecas\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# carga dos dados\n","nairobi_raw = pd.read_csv(\"data/nairobi_raw.csv\", delimiter = \";\", decimal = \",\")\n","print(nairobi_raw.shape)\n","nairobi_raw.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CCJKwisylIu0"},"source":["Como nosso conjunto de dados claramente não está pronto para ser utilizado por nosso algoritmo de aprendizado de máquina, faremos a preparação de alguns dados nele.\n","\n","Podemos ver que temos mais de 50 mil observações e 7 variáveis. Mas onde está a variável que devemos prever, a quantidade de passageiros em cada viagem de ônibus? Cada viagem de ônibus tem um ID de viagem e cada observação neste conjunto de dados é o registro de um passageiro que comprou uma passagem para estar naquele ônibus. Portanto, vamos apenas agrupar os passageiros pelo ID da viagem! Problema resolvido? Quase lá.\n","\n","Vamos remover a variável _travel_to_, pois todas as viagens são para Nairóbi. Além disso, vamos ajudar nosso modelo de árvore de decisão e criar algumas variáveis que indicam 4 intervalos de tempo diferentes para as viagens acontecerem. Esses intervalos foram criados mais ou menos com base na quantidade de viagens em cada hora do dia.\n","\n","Portanto, este é nosso novo conjunto de dados após alguma transformação:"]},{"cell_type":"code","metadata":{"id":"XMVWp8gqlIu1"},"source":["# import da base de dados transformada\n","nairobi_treated = pd.read_csv(\"data/nairobi_treated.csv\", delimiter = \";\", decimal = \",\")\n","\n","# vamos definir a data como o indide do dataset\n","nairobi_treated.index = nairobi_treated['travel_date']\n","nairobi_treated = nairobi_treated.iloc[:, 1:]\n","\n","# prints das características do dataset\n","print(nairobi_treated.shape)\n","nairobi_treated.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AAaTuaX2lIu5"},"source":["Agora que importamos nosso banco de dados, vamos separar a variável objetivo das demais variávels. Nossa variável objetivo será _nb_passengers_, que é o número de passageiros em cada viagem."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Z4unEz_PlIu6"},"source":["# separando variável objetivo\n","X, y = nairobi_treated.iloc[:, :-1], nairobi_treated.iloc[:, -1]\n","\n","print(\"X\", X.shape)\n","print(X.head())\n","print(\"y\", y.shape)\n","print(y.head)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYyb7E_8lIu9"},"source":["Como nós temos variáveis categóricas, vamos transformá-las em dummy:"]},{"cell_type":"code","metadata":{"id":"mLLsaIpplIu-"},"source":["X = pd.get_dummies(X)\n","X.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"293UONfElIvB"},"source":["Agora vamos dividir nosso conjunto de dados em conjuntos de treinamento e teste. Definir _shuffle = False_ significa que dividiremos o treinamento e o teste seguindo a ordem das observações, que são classificadas por data."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"lopifLgflIvC"},"source":["# import função train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# usamos a função train_test_split para criar os sets de treino e teste\n","# define o tamanho do set de teste. Pode ser um inteiro (número de observações) ou então uma fração, correspondendo à proporção treino/teste\n","# suffle = False significa que a separação obedecerá a sequencia da data\n","X_training, X_test, y_training, y_test = train_test_split(X, y, \n","                                                          test_size = 0.25, \n","                                                          shuffle = False)\n","\n","print(\"Train set X\", X_training.shape)\n","print(\"Train set y\", y_training.shape)\n","print(\"Test set X\", X_test.shape)\n","print(\"Test set y\", y_test.shape)\n","X_test.head()\n","X_test_backup = X_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IpctDWGplIvF"},"source":["Agora, vamos explorar a técnica de divisão que aprendemos anteriormente nesta lição, usando a função TimeSeriesSplit. Nosso número de divisões será 10 e usaremos todo o histórico disponível para o conjunto de dados de treinamento."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"HMeIBPOXlIvF"},"source":["from sklearn.model_selection import TimeSeriesSplit\n","cv = TimeSeriesSplit(n_splits=10)\n","\n","# plot do dataset para validação cruzada\n","fig, ax = plt.subplots(figsize=(10, 5))\n","for index, (X_train, X_test) in enumerate(cv.split(X)):\n","    # Plot índices de treino e teste\n","    l1 = ax.scatter(X_train, [index] * len(X_train), c=[plt.cm.coolwarm(.1)], marker='_', lw=6)\n","    l2 = ax.scatter(X_test, [index] * len(X_test), c=[plt.cm.coolwarm(.9)], marker='_', lw=6)\n","    ax.set(ylim=[10, -1], title='TimeSeriesSplit behavior', xlabel='data index', ylabel='CV iteration')\n","    ax.legend([l1, l2], ['Training', 'Validation'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nqu2L5NHlIvI"},"source":["Agora vamos treinar nosso modelo de árvore com _Grid Search_ e a técnica de validação cruzada de divisão de série temporal. Como nosso conjunto de dados é meio grande e o _Grid Search_ demoraria (e demorou), já definimos os melhores parâmetros para você!"]},{"cell_type":"code","metadata":{"id":"Gf3UVeJalIvI"},"source":["# Import das bibliotecas usadas\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.datasets import make_regression\n","from sklearn.metrics import (explained_variance_score, \n","                             mean_absolute_error, \n","                             mean_squared_error, \n","                             mean_squared_log_error,\n","                             r2_score)\n","from sklearn.model_selection import GridSearchCV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"L2pFL5rNlIvK"},"source":["# Random Forest com Validação cruzada e Grid Search para Séries temporais\n","\n","# define os valores possíveis para os parâmetros a serem testados\n","params = {'n_estimators': [100, 500],\n","          'max_features': [3, 5],\n","          'max_depth': [5, 10]}\n","\n","# cria modelo\n","rf_model_cv_gs = RandomForestRegressor()\n","\n","# objeto para grid search com GridSearchCV\n","grid_search = GridSearchCV(rf_model_cv_gs, \n","                           param_grid = params, \n","                           return_train_score = True, \n","                           cv = cv)\n","\n","# treina modelo com Grid Search\n","grid_search.fit(X_training, y_training)\n","\n","# imprime melhor combinação de hiperparâmetros\n","print('\\n Best hyperparameters:')\n","print(grid_search.best_params_)\n","\n","# resultados do cv\n","cv_results = pd.DataFrame(grid_search.cv_results_)\n","\n","# print score médio nos sets de treino e teste\n","print(\"Average Score on train set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_train_score.values[0]))\n","# print score médio nos sets de validação\n","print(\"Average Score on validation set: {:.3f} +/- {:.3f}\".format(cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0],\n","                                                                     cv_results[cv_results.rank_test_score == 1].std_test_score.values[0])) \n","\n","y = [cv_results[cv_results.rank_test_score == 1].mean_train_score.values[0], \n","     cv_results[cv_results.rank_test_score == 1].mean_test_score.values[0]]\n","x = [\"Train Score\", \"Test Score\"]\n","width = 1/2\n","plt.bar(x, y, width, color=\"blue\")  \n","\n","# seta melhor opção baseada nos hiperparâmetros\n","# utiliza as melhores opções de hiperparâmetros encontrados\n","rf_model_cv_gs.set_params(n_estimators = grid_search.best_params_['n_estimators'],\n","                           max_features = grid_search.best_params_['max_features'],\n","                           max_depth = grid_search.best_params_['max_depth'])\n","\n","# treina modelo com os melhores hiperparâmetros\n","rf_model_cv_gs.fit(X_training, y_training)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"irsnnwVilIvN"},"source":["Vamos calcular o MAE para treino e teste:"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"yYq5bH45lIvO"},"source":["print(\"MAE train:\", mean_absolute_error(y_training, rf_model_cv_gs.predict(X_training)))\n","print(\"MAE test:\", mean_absolute_error(y_test, rf_model_cv_gs.predict(X_test_backup)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcYwGcdHfkN7"},"source":["###5. Exercício"]},{"cell_type":"markdown","metadata":{"id":"Hci8zeHNfi70"},"source":["O conjunto de dados abaixo origina-se originalmente de um desafio de recrutamento do Walmart, que pode ser acessado [aqui](https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting/data). Ele contém vendas anônimas por departamento para 45 lojas Walmart, bem como recursos de apoio.\n","\n","O exercício proposto é para prever as vendas semanais. Utilize o modelo de machine learning 'Random Forest'"]},{"cell_type":"code","metadata":{"id":"U4FSOilqfsL2"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","walmart = pd.read_csv(\"data/walmart_sales.csv\")\n","\n","print(walmart.shape)\n","walmart.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h7yYHfr-i7iE"},"source":["####Parte 1: Pré processamento de Dados"]},{"cell_type":"code","metadata":{"id":"zLUDh2P5f3Zo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oPrS4ZAIjJx-"},"source":["####Parte 2: Separação de Sets de Treino e Teste"]},{"cell_type":"code","metadata":{"id":"qSei7y0zgSh5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACcJCtx9jTcC"},"source":["####Parte 3: Construção do modelo e resultados\n","\n"]},{"cell_type":"code","metadata":{"id":"YnO7zxGPgaW1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l5RlwVVBlIwe"},"source":["## Aprofundamento\n","\n","- [Forecasting: Principles and Practice](https://otexts.com/fpp3/)\n","- [Time Series Databases are Exploding in Popularity](https://www.techrepublic.com/article/why-time-series-databases-are-exploding-in-popularity/)\n","- [Application of Different Long Short-Term Memory Algorithms](https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/)\n","- [How (not) to use Machine Learning for time series forecasting: Avoiding the pitfalls](https://towardsdatascience.com/how-not-to-use-machine-learning-for-time-series-forecasting-avoiding-the-pitfalls-19f9d7adf424)\n","- [Applied Forecasting for Business and Economics](https://robjhyndman.com/teaching/)\n","- [Time Series Forecast: A Basic Introduction Using Python](https://medium.com/@stallonejacob/time-series-forecast-a-basic-introduction-using-python-414fcb963000)\n","- [Time Series Forecast with Prophet](https://towardsdatascience.com/time-series-forecasting-with-prophet-54f2ac5e722e)\n","- [Facebook Prophet Webpage](https://research.fb.com/prophet-forecasting-at-scale/)\n","- [How to Rock Your Next Time Series Forecasting Project](https://medium.com/free-code-camp/how-to-rock-your-next-time-series-forecasting-project-3930d589f704)\n","- [An End-to-end Project on Time Series Forecasting](https://towardsdatascience.com/an-end-to-end-project-on-time-series-analysis-and-forecasting-with-python-4835e6bf050b)"]}]}